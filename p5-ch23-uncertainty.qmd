# Uncertainty Quantification {#sec-uncertainty}
**Label**: `@sec-uncertainty`  
**Old source**: **NEW CHAPTER**

**Conceptual goals**:
- Distinguish types of uncertainty in genomic predictions
- Understand calibration and why it matters for decisions
- Apply practical UQ methods to foundation models

**Key concepts**:
- Epistemic vs. aleatoric uncertainty
- Calibration: do confidence scores mean what they say?
- Calibration metrics: ECE, reliability diagrams
- Approaches: ensembles, MC dropout, temperature scaling, conformal prediction
- Out-of-distribution detection: when models don't know
- Selective prediction: abstaining when uncertain
- Communicating uncertainty to users (clinicians, researchers)

**Pedagogical arc**:
1. Open with the clinical need: not just "pathogenic" but "how confident?"
2. Distinguish epistemic (model uncertainty) from aleatoric (data uncertainty)
3. Explain calibration and why most models are miscalibrated
4. Cover calibration assessment methods
5. Introduce UQ approaches for foundation models
6. Discuss OOD detection: recognizing unfamiliar inputs
7. Address selective prediction and abstention
8. Cover communication challenges
9. Close with: uncertainty is essential for trustworthy deployment

**Connections**:
- Back to Ch 14 (VEP uncertainty)
- Back to Ch 21 (calibration metrics in evaluation)
- Forward to Ch 25 (UQ in clinical risk prediction)
- Forward to Ch 26 (uncertainty in variant interpretation)

**Content sources**: This is new content. Draw on: conformal prediction literature, temperature scaling [@guo_calibration_2017], ensemble methods, recent work on LLM calibration.