@article{landrum_clinvar_2018,
	title = {{ClinVar}: improving access to variant interpretations and supporting evidence},
	volume = {46},
	issn = {0305-1048},
	shorttitle = {{ClinVar}},
	url = {https://doi.org/10.1093/nar/gkx1153},
	doi = {10.1093/nar/gkx1153},
	abstract = {ClinVar (https://www.ncbi.nlm.nih.gov/clinvar/) is a freely available, public archive of human genetic variants and interpretations of their significance to disease, maintained at the National Institutes of Health. Interpretations of the clinical significance of variants are submitted by clinical testing laboratories, research laboratories, expert panels and other groups. ClinVar aggregates data by variant-disease pairs, and by variant (or set of variants). Data aggregated by variant are accessible on the website, in an improved set of variant call format files and as a new comprehensive XML report. ClinVar recently started accepting submissions that are focused primarily on providing phenotypic information for individuals who have had genetic testing. Submissions may come from clinical providers providing their own interpretation of the variant (‘provider interpretation’) or from groups such as patient registries that primarily provide phenotypic information from patients (‘phenotyping only’). ClinVar continues to make improvements to its search and retrieval functions. Several new fields are now indexed for more precise searching, and filters allow the user to narrow down a large set of search results.},
	number = {D1},
	urldate = {2025-12-06},
	journal = {Nucleic Acids Research},
	author = {Landrum, Melissa J and Lee, Jennifer M and Benson, Mark and Brown, Garth R and Chao, Chen and Chitipiralla, Shanmuga and Gu, Baoshan and Hart, Jennifer and Hoffman, Douglas and Jang, Wonhee and Karapetyan, Karen and Katz, Kenneth and Liu, Chunlei and Maddipatla, Zenith and Malheiro, Adriana and McDaniel, Kurt and Ovetsky, Michael and Riley, George and Zhou, George and Holmes, J Bradley and Kattman, Brandi L and Maglott, Donna R},
	month = jan,
	year = {2018},
	pages = {D1062--D1067},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/PBKZHYPQ/2018-01-04 - Landrum et al. - ClinVar improving access to variant interpretations and supporting evidence.pdf:application/pdf;Snapshot:/Users/meehl.joshua/Zotero/storage/F7C3YBZY/gkx1153.html:text/html},
}

@inproceedings{guo_calibration_2017,
	title = {On {Calibration} of {Modern} {Neural} {Networks}},
	url = {https://proceedings.mlr.press/v70/guo17a.html},
	abstract = {Confidence calibration – the problem of predicting probability estimates representative of the true correctness likelihood – is important for classification models in many applications. We discover that modern neural networks, unlike those from a decade ago, are poorly calibrated. Through extensive experiments, we observe that depth, width, weight decay, and Batch Normalization are important factors influencing calibration. We evaluate the performance of various post-processing calibration methods on state-of-the-art architectures with image and document classification datasets. Our analysis and experiments not only offer insights into neural network learning, but also provide a simple and straightforward recipe for practical settings: on most datasets, temperature scaling – a single-parameter variant of Platt Scaling – is surprisingly effective at calibrating predictions.},
	language = {en},
	urldate = {2025-12-23},
	booktitle = {Proceedings of the 34th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Guo, Chuan and Pleiss, Geoff and Sun, Yu and Weinberger, Kilian Q.},
	month = jul,
	year = {2017},
	note = {ISSN: 2640-3498},
	pages = {1321--1330},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/DKBPJ3LH/2017-07-17 - Guo et al. - On Calibration of Modern Neural Networks.pdf:application/pdf;Supplementary PDF:/Users/meehl.joshua/Zotero/storage/MCDJSU35/2017-07-17 - Guo et al. - On Calibration of Modern Neural Networks.pdf:application/pdf},
}

@article{rubin_statistical_2017,
	title = {A statistical framework for analyzing deep mutational scanning data},
	volume = {18},
	issn = {1474-760X},
	url = {https://doi.org/10.1186/s13059-017-1272-5},
	doi = {10.1186/s13059-017-1272-5},
	abstract = {Deep mutational scanning is a widely used method for multiplex measurement of functional consequences of protein variants. We developed a new deep mutational scanning statistical model that generates error estimates for each measurement, capturing both sampling error and consistency between replicates. We apply our model to one novel and five published datasets comprising 243,732 variants and demonstrate its superiority in removing noisy variants and conducting hypothesis testing. Simulations show our model applies to scans based on cell growth or binding and handles common experimental errors. We implemented our model in Enrich2, software that can empower researchers analyzing deep mutational scanning data.},
	language = {en},
	number = {1},
	urldate = {2025-12-24},
	journal = {Genome Biology},
	author = {Rubin, Alan F. and Gelman, Hannah and Lucas, Nathan and Bajjalieh, Sandra M. and Papenfuss, Anthony T. and Speed, Terence P. and Fowler, Douglas M.},
	month = aug,
	year = {2017},
	pages = {150},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/P3UYURD5/2017-08-07 - Rubin et al. - A statistical framework for analyzing deep mutational scanning data.pdf:application/pdf},
}

@article{fowler_deep_2014,
	title = {Deep mutational scanning: a new style of protein science},
	volume = {11},
	copyright = {2014 Springer Nature America, Inc.},
	issn = {1548-7105},
	shorttitle = {Deep mutational scanning},
	url = {https://www.nature.com/articles/nmeth.3027},
	doi = {10.1038/nmeth.3027},
	abstract = {This Perspective discusses the power of large mutational scans for the study of protein properties, the analytical challenges posed by the resulting data sets and the potential of this approach to further our understanding of human genetic variation.},
	language = {en},
	number = {8},
	urldate = {2025-12-24},
	journal = {Nature Methods},
	author = {Fowler, Douglas M. and Fields, Stanley},
	month = aug,
	year = {2014},
	note = {Publisher: Nature Publishing Group},
	pages = {801--807},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/4WE7ARDU/2014-08 - Fowler and Fields - Deep mutational scanning a new style of protein science.pdf:application/pdf},
}

@inproceedings{gal_dropout_2016,
	title = {Dropout as a {Bayesian} {Approximation}: {Representing} {Model} {Uncertainty} in {Deep} {Learning}},
	shorttitle = {Dropout as a {Bayesian} {Approximation}},
	url = {https://proceedings.mlr.press/v48/gal16.html},
	abstract = {Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs – extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout’s uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout’s uncertainty in deep reinforcement learning.},
	language = {en},
	urldate = {2025-12-24},
	booktitle = {Proceedings of {The} 33rd {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Gal, Yarin and Ghahramani, Zoubin},
	month = jun,
	year = {2016},
	note = {ISSN: 1938-7228},
	pages = {1050--1059},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/FJC5JRJ4/2016-06-11 - Gal and Ghahramani - Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning.pdf:application/pdf},
}