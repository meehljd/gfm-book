@article{benegas_gpn_2023,
	title = {[{GPN}] {DNA} language models are powerful predictors of genome-wide variant effects},
	volume = {120},
	url = {https://www.pnas.org/doi/10.1073/pnas.2311219120},
	doi = {10.1073/pnas.2311219120},
	abstract = {The expanding catalog of genome-wide association studies (GWAS) provides biological insights across a variety of species, but identifying the causal variants behind these associations remains a significant challenge. Experimental validation is both labor-intensive and costly, highlighting the need for accurate, scalable computational methods to predict the effects of genetic variants across the entire genome. Inspired by recent progress in natural language processing, unsupervised pretraining on large protein sequence databases has proven successful in extracting complex information related to proteins. These models showcase their ability to learn variant effects in coding regions using an unsupervised approach. Expanding on this idea, we here introduce the Genomic Pre-trained Network (GPN), a model designed to learn genome-wide variant effects through unsupervised pretraining on genomic DNA sequences. Our model also successfully learns gene structure and DNA motifs without any supervision. To demonstrate its utility, we train GPN on unaligned reference genomes of Arabidopsis thaliana and seven related species within the Brassicales order and evaluate its ability to predict the functional impact of genetic variants in A. thaliana by utilizing allele frequencies from the 1001 Genomes Project and a comprehensive database of GWAS. Notably, GPN outperforms predictors based on popular conservation scores such as phyloP and phastCons. Our predictions for A. thaliana can be visualized as sequence logos in the UCSC Genome Browser (https://genome.ucsc.edu/s/gbenegas/gpn-arabidopsis). We provide code (https://github.com/songlab-cal/gpn) to train GPN for any given species using its DNA sequence alone, enabling unsupervised prediction of variant effects across the entire genome.},
	number = {44},
	urldate = {2023-11-16},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Benegas, Gonzalo and Batra, Sanjit Singh and Song, Yun S.},
	month = oct,
	year = {2023},
	note = {81 citations (Crossref/DOI) [2025-10-22]
Publisher: Proceedings of the National Academy of Sciences},
	keywords = {Printed, Read},
	pages = {e2311219120},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/YLQDHAPZ/2023-10-31 - Benegas et al. - [GPN] DNA language models are powerful predictors of genome-wide variant effects.pdf:application/pdf},
}

@misc{camillo_cpgpt_2024,
	title = {{CpGPT}: a {Foundation} {Model} for {DNA} {Methylation}},
	copyright = {© 2024, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	shorttitle = {{CpGPT}},
	url = {https://www.biorxiv.org/content/10.1101/2024.10.24.619766v1},
	doi = {10.1101/2024.10.24.619766},
	abstract = {DNA methylation is a critical epigenetic modification that regulates gene expression and plays a significant role in development and disease processes. Here, we present the Cytosine-phosphate-Guanine Pretrained Transformer (CpGPT), a novel foundation model pretrained on over 1,500 DNA methylation datasets encompassing over 100,000 samples from diverse tissues and conditions. CpGPT leverages an improved transformer architecture to learn comprehensive representations of methylation patterns, allowing it to impute and reconstruct genome-wide methylation profiles from limited input data. By capturing sequence, positional, and epigenetic contexts, CpGPT outperforms specialized models when finetuned for aging-related tasks, including chronological age prediction, mortality risk, and morbidity assessments. The model is highly adaptable across different methylation platforms and tissue types. Furthermore, analysis of sample-specific attention weights enables the identification of the most influential CpG sites for individual predictions. As a foundation model, CpGPT sets a new benchmark for DNA methylation analysis, achieving strong performance in the Biomarkers of Aging Challenge, where it placed second overall in chronological age estimation and first on the public leaderboard in methylation-based mortality prediction.
HighlightsCpGPT is a novel foundation model for DNA methylation analysis, pretrained on over 1,500 datasets encompassing 100,000+ samples.The model demonstrates strong performance in zero-shot tasks including imputation, array conversion, and reference mapping.CpGPT achieves state-of-the-art results in mortality prediction and chronological age estimation.Sample-specific interpretability is enabled through analysis of attention weights.},
	language = {en},
	urldate = {2025-07-05},
	publisher = {bioRxiv},
	author = {Camillo, Lucas Paulo de Lima and Sehgal, Raghav and Armstrong, Jenel and Higgins-Chen, Albert T. and Horvath, Steve and Wang, Bo},
	month = oct,
	year = {2024},
	note = {17 citations (Crossref/DOI) [2025-10-22]
Pages: 2024.10.24.619766
Section: New Results},
	keywords = {Printed, Podcast},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/BD6NXKAF/2024-10-29 - Camillo et al. - CpGPT a Foundation Model for DNA Methylation.pdf:application/pdf},
}

@article{cao_glue_2022,
	title = {[{GLUE}] {Multi}-omics single-cell data integration and regulatory inference with graph-linked embedding},
	volume = {40},
	copyright = {2022 The Author(s)},
	issn = {1546-1696},
	url = {https://www.nature.com/articles/s41587-022-01284-4},
	doi = {10.1038/s41587-022-01284-4},
	abstract = {Despite the emergence of experimental methods for simultaneous measurement of multiple omics modalities in single cells, most single-cell datasets include only one modality. A major obstacle in integrating omics data from multiple modalities is that different omics layers typically have distinct feature spaces. Here, we propose a computational framework called GLUE (graph-linked unified embedding), which bridges the gap by modeling regulatory interactions across omics layers explicitly. Systematic benchmarking demonstrated that GLUE is more accurate, robust and scalable than state-of-the-art tools for heterogeneous single-cell multi-omics data. We applied GLUE to various challenging tasks, including triple-omics integration, integrative regulatory inference and multi-omics human cell atlas construction over millions of cells, where GLUE was able to correct previous annotations. GLUE features a modular design that can be flexibly extended and enhanced for new analysis tasks. The full package is available online at https://github.com/gao-lab/GLUE.},
	language = {en},
	number = {10},
	urldate = {2025-07-12},
	journal = {Nature Biotechnology},
	author = {Cao, Zhi-Jie and Gao, Ge},
	month = may,
	year = {2022},
	note = {397 citations (Crossref/DOI) [2025-10-22]
Publisher: Nature Publishing Group},
	keywords = {Printed, Read},
	pages = {1458--1466},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/M96CQGML/2022-05-02 - Cao and Gao - [GLUE] Multi-omics single-cell data integration and regulatory inference with graph-linked embedding.pdf:application/pdf},
}

@article{clarke_deeprvat_2024,
	title = {[{DeepRVAT}] {Integration} of variant annotations using deep set networks boosts rare variant association testing},
	volume = {56},
	copyright = {2024 The Author(s)},
	issn = {1546-1718},
	url = {https://www.nature.com/articles/s41588-024-01919-z},
	doi = {10.1038/s41588-024-01919-z},
	abstract = {Rare genetic variants can have strong effects on phenotypes, yet accounting for rare variants in genetic analyses is statistically challenging due to the limited number of allele carriers and the burden of multiple testing. While rich variant annotations promise to enable well-powered rare variant association tests, methods integrating variant annotations in a data-driven manner are lacking. Here we propose deep rare variant association testing (DeepRVAT), a model based on set neural networks that learns a trait-agnostic gene impairment score from rare variant annotations and phenotypes, enabling both gene discovery and trait prediction. On 34 quantitative and 63 binary traits, using whole-exome-sequencing data from UK Biobank, we find that DeepRVAT yields substantial gains in gene discoveries and improved detection of individuals at high genetic risk. Finally, we demonstrate how DeepRVAT enables calibrated and computationally efficient rare variant tests at biobank scale, aiding the discovery of genetic risk factors for human disease traits.},
	language = {en},
	number = {10},
	urldate = {2025-07-12},
	journal = {Nature Genetics},
	author = {Clarke, Brian and Holtkamp, Eva and Öztürk, Hakime and Mück, Marcel and Wahlberg, Magnus and Meyer, Kayla and Munzlinger, Felix and Brechtmann, Felix and Hölzlwimmer, Florian R. and Lindner, Jonas and Chen, Zhifen and Gagneur, Julien and Stegle, Oliver},
	month = sep,
	year = {2024},
	note = {12 citations (Crossref/DOI) [2025-10-22]
Publisher: Nature Publishing Group},
	keywords = {Printed, Podcast},
	pages = {2271--2280},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/G5IIH2WR/2024-09-25 - Clarke et al. - [DeepRVAT] Integration of variant annotations using deep set networks boosts rare variant associatio.pdf:application/pdf},
}

@article{dalla-torre_nucleotide_2023,
	title = {Nucleotide {Transformer}: building and evaluating robust foundation models for human genomics},
	volume = {22},
	copyright = {2024 The Author(s)},
	issn = {1548-7105},
	shorttitle = {Nucleotide {Transformer}},
	url = {https://www.nature.com/articles/s41592-024-02523-z},
	doi = {10.1038/s41592-024-02523-z},
	abstract = {The prediction of molecular phenotypes from DNA sequences remains a longstanding challenge in genomics, often driven by limited annotated data and the inability to transfer learnings between tasks. Here, we present an extensive study of foundation models pre-trained on DNA sequences, named Nucleotide Transformer, ranging from 50 million up to 2.5 billion parameters and integrating information from 3,202 human genomes and 850 genomes from diverse species. These transformer models yield context-specific representations of nucleotide sequences, which allow for accurate predictions even in low-data settings. We show that the developed models can be fine-tuned at low cost to solve a variety of genomics applications. Despite no supervision, the models learned to focus attention on key genomic elements and can be used to improve the prioritization of genetic variants. The training and application of foundational models in genomics provides a widely applicable approach for accurate molecular phenotype prediction from DNA sequence.},
	language = {en},
	number = {2},
	urldate = {2025-04-16},
	journal = {Nature Methods},
	author = {Dalla-Torre, Hugo and Gonzalez, Liam and Mendoza-Revilla, Javier and Lopez Carranza, Nicolas and Grzywaczewski, Adam Henryk and Oteri, Francesco and Dallago, Christian and Trop, Evan and de Almeida, Bernardo P. and Sirelkhatim, Hassan and Richard, Guillaume and Skwark, Marcin and Beguir, Karim and Lopez, Marie and Pierrot, Thomas},
	month = jan,
	year = {2023},
	note = {123 citations (Crossref/DOI) [2025-10-22]
Publisher: Nature Publishing Group},
	keywords = {Printed, Important, Podcast, Read},
	pages = {287--297},
	file = {[Preprint] Dalla-Torre et al. - 2023 - Nucleotide Transformer building and evaluating robust foundation models for human genomics:/Users/meehl.joshua/Zotero/storage/METWGZEF/2023-01-15 - Dalla-Torre et al. - Nucleotide Transformer building and evaluating robust foundation models for human genomics.pdf:application/pdf;Full Text PDF:/Users/meehl.joshua/Zotero/storage/K28P6JFS/2023-01-15 - Dalla-Torre et al. - Nucleotide Transformer building and evaluating robust foundation models for human genomics.pdf:application/pdf},
}

@misc{georgantas_delphi_2024,
	title = {Delphi: {A} {Deep}-learning {Method} for {Polygenic} {Risk} {Prediction}},
	copyright = {© 2024, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	shorttitle = {Delphi},
	url = {https://www.medrxiv.org/content/10.1101/2024.04.19.24306079v2},
	doi = {10.1101/2024.04.19.24306079},
	abstract = {Polygenic risk scores (PRS) are relative measures of an individual’s genetic propensity to a particular trait or disease. Most PRS methods assume that mutation effects scale linearly with the number of alleles and are constant across individuals. While these assumptions simplify computation, they increase error, particularly for less-represented racial groups. We developed and provide Delphi (deep learning for phenotype inference), a deep-learning method that relaxes these assumptions to produce more predictive PRS. In contrast to other methods, Delphi can integrate up to hundreds of thousands of SNPs as input. We compare our results to a standard, linear PRS model, lasso regression, and a gradient-boosted trees-based method. We show that deep learning can be an effective approach to genetic risk prediction. We report a relative increase in the percentage variance explained compared to the state-of-the-art by 11.4\% for body mass index, 18.9\% for systolic blood pressure, 7.5\% for LDL, 35\% for C-reactive protein, 16.2\% for height, 29.6 \% for pulse rate; in addition, Delphi provides 2\% absolute explained variance for blood glucose while other tested methods were non-predictive. Furthermore, we show that Delphi tends to increase the weight of high-effect mutations. This work demonstrates an effective deep learning method for modeling genetic risk that also showed to generalize well when evaluated on individuals from non-European ancestries.},
	language = {en},
	urldate = {2025-07-12},
	publisher = {medRxiv},
	author = {Georgantas, Costa and Kutalik, Zoltán and Richiardi, Jonas},
	month = jul,
	year = {2024},
	note = {3 citations (Crossref/DOI) [2025-10-22]
Pages: 2024.04.19.24306079},
	keywords = {Printed, Podcast},
	file = {PDF:/Users/meehl.joshua/Zotero/storage/YHXTGSCR/2024-07-02 - Georgantas et al. - Delphi A Deep-learning Method for Polygenic Risk Prediction.pdf:application/pdf},
}

@article{jurenaite_setquence_2024,
	title = {{SetQuence} \& {SetOmic}: {Deep} set transformers for whole genome and exome tumour analysis},
	volume = {235},
	issn = {0303-2647},
	shorttitle = {{SetQuence} \& {SetOmic}},
	url = {https://www.sciencedirect.com/science/article/pii/S0303264723002708},
	doi = {10.1016/j.biosystems.2023.105095},
	abstract = {In oncology, Deep Learning has shown great potential to personalise tasks such as tumour type classification, based on per-patient omics data-sets. Being high dimensional, incorporation of such data in one model is a challenge, often leading to one-dimensional studies and, therefore, information loss. Instead, we first propose relying on non-fixed sets of whole genome or whole exome variant-associated sequences, which can be used for supervised learning of oncology-relevant tasks by our Set Transformer based Deep Neural Network, SetQuence. We optimise this architecture to improve its efficiency. This allows for exploration of not just coding but also non-coding variants, from large datasets. Second, we extend the model to incorporate these representations together with multiple other sources of omics data in a flexible way with SetOmic. Evaluation, using these representations, shows improved robustness and reduced information loss compared to previous approaches, while still being computationally tractable. By means of Explainable Artificial Intelligence methods, our models are able to recapitulate the biological contribution of highly attributed features in the tumours studied. This validation opens the door to novel directions in multi-faceted genome and exome wide biomarker discovery and personalised treatment among other presently clinically relevant tasks.},
	urldate = {2025-05-28},
	journal = {BioSystems},
	author = {Jurenaite, Neringa and León-Periñán, Daniel and Donath, Veronika and Torge, Sunna and Jäkel, René},
	month = jan,
	year = {2024},
	note = {4 citations (Crossref/DOI) [2025-10-22]},
	keywords = {Printed, Podcast, Read},
	pages = {105095},
	file = {Accepted Version:/Users/meehl.joshua/Zotero/storage/FLZFTRF2/2024-01-01 - Jurenaite et al. - SetQuence & SetOmic Deep set transformers for whole genome and exome tumour analysis.pdf:application/pdf;ScienceDirect Snapshot:/Users/meehl.joshua/Zotero/storage/AW65ASE7/S0303264723002708.html:text/html},
}

@misc{lee_g2pt_2025,
	title = {[{G2PT}] {A} genotype-phenotype transformer to assess and explain polygenic risk},
	copyright = {© 2025, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/2024.10.23.619940v2},
	doi = {10.1101/2024.10.23.619940},
	abstract = {Genome-wide association studies have linked millions of genetic variants to biomedical phenotypes, but their utility has been limited by lack of mechanistic understanding and widespread epistatic interactions. Recently, Transformer models have emerged as a powerful machine learning architecture with potential to address these and other challenges. Accordingly, here we introduce the Genotype-to-Phenotype Transformer (G2PT), a framework for modeling hierarchical information flow among variants, genes, multigenic systems, and phenotypes. As proof-of-concept, we use G2PT to model the genetics of TG/HDL (triglycerides to high-density lipoprotein cholesterol), an indicator of metabolic health. G2PT predicts this trait via attention to 1,395 variants underlying at least 20 systems, including immune response and cholesterol transport, with accuracy exceeding state-of-the-art. It implicates 40 epistatic interactions, including epistasis between APOA4 and CETP in phospholipid transfer, a target pathway for cholesterol modification. This work positions hierarchical graph transformers as a next-generation approach to polygenic risk.},
	language = {en},
	urldate = {2025-05-28},
	publisher = {bioRxiv},
	author = {Lee, Ingoo and Wallace, Zachary S. and Wang, Yuqi and Park, Sungjoon and Nam, Hojung and Majithia, Amit R. and Ideker, Trey},
	month = apr,
	year = {2025},
	note = {1 citations (Crossref/DOI) [2025-10-22]
Pages: 2024.10.23.619940
Section: New Results},
	keywords = {Printed, Podcast, Recall},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/2ZPTDM6K/2025-04-11 - Lee et al. - [G2PT] A genotype-phenotype transformer to assess and explain polygenic risk.pdf:application/pdf},
}

@article{li_mogcn_2022,
	title = {{MoGCN}: {A} {Multi}-{Omics} {Integration} {Method} {Based} on {Graph} {Convolutional} {Network} for {Cancer} {Subtype} {Analysis}},
	volume = {13},
	issn = {1664-8021},
	shorttitle = {{MoGCN}},
	url = {https://www.frontiersin.org/journals/genetics/articles/10.3389/fgene.2022.806842/full},
	doi = {10.3389/fgene.2022.806842},
	abstract = {In light of the rapid accumulation of large-scale omics datasets, numerous studies have attempted to characterize the molecular and clinical features of cancers from a multi-omics perspective. However, there are great challenges in integrating multi-omics using machine learning methods for cancer subtype classification. In this study, MoGCN, a multi-omics integration model based on graph convolutional network (GCN) was developed for cancer subtype classification and analysis. Genomics, transcriptomics and proteomics datasets for 511 breast invasive carcinoma (BRCA) samples were downloaded from the Cancer Genome Atlas (TCGA). The autoencoder (AE) and the similarity network fusion (SNF) methods were used to reduce dimensionality and construct the patient similarity network (PSN), respectively. Then the vector features and the PSN were input into the GCN for training and testing. Feature extraction and network visualization were used for further biological knowledge discovery and subtype classification. In the analysis of multi-dimensional omics data of the BRCA samples in TCGA, MoGCN achieved the highest accuracy in cancer subtype classification compared with several popular algorithms. Moreover, MoGCN can extract the most significant features of each omics layer and provide candidate functional molecules for further analysis of their biological effects. And network visualization showed that MoGCN could make clinically intuitive diagnosis. The generality of MoGCN was proven on the TCGA pan-kidney cancer datasets. MoGCN and datasets are public available at https://github.com/Lifoof/MoGCN. Our study shows that MoGCN performs well for heterogeneous data integration and the interpretability of classification results, which confers great potential for applications in biomarker identification and clinical diagnosis.},
	language = {English},
	urldate = {2025-07-12},
	journal = {Frontiers in Genetics},
	author = {Li, Xiao and Ma, Jie and Leng, Ling and Han, Mingfei and Li, Mansheng and He, Fuchu and Zhu, Yunping},
	month = feb,
	year = {2022},
	note = {90 citations (Crossref/DOI) [2025-10-22]
Publisher: Frontiers},
	keywords = {Printed, Read},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/NTWP6PXW/2022-02-02 - Li et al. - MoGCN A Multi-Omics Integration Method Based on Graph Convolutional Network for Cancer Subtype Anal.pdf:application/pdf},
}

@misc{nguyen_hyenadna_2023,
	title = {{HyenaDNA}: {Long}-{Range} {Genomic} {Sequence} {Modeling} at {Single} {Nucleotide} {Resolution}},
	shorttitle = {{HyenaDNA}},
	url = {http://arxiv.org/abs/2306.15794},
	doi = {10.48550/arXiv.2306.15794},
	abstract = {Genomic (DNA) sequences encode an enormous amount of information for gene regulation and protein synthesis. Similar to natural language models, researchers have proposed foundation models in genomics to learn generalizable features from unlabeled genome data that can then be fine-tuned for downstream tasks such as identifying regulatory elements. Due to the quadratic scaling of attention, previous Transformer-based genomic models have used 512 to 4k tokens as context ({\textless}0.001\% of the human genome), significantly limiting the modeling of long-range interactions in DNA. In addition, these methods rely on tokenizers or fixed k-mers to aggregate meaningful DNA units, losing single nucleotide resolution where subtle genetic variations can completely alter protein function via single nucleotide polymorphisms (SNPs). Recently, Hyena, a large language model based on implicit convolutions was shown to match attention in quality while allowing longer context lengths and lower time complexity. Leveraging Hyena's new long-range capabilities, we present HyenaDNA, a genomic foundation model pretrained on the human reference genome with context lengths of up to 1 million tokens at the single nucleotide-level - an up to 500x increase over previous dense attention-based models. HyenaDNA scales sub-quadratically in sequence length (training up to 160x faster than Transformer), uses single nucleotide tokens, and has full global context at each layer. We explore what longer context enables - including the first use of in-context learning in genomics. On fine-tuned benchmarks from the Nucleotide Transformer, HyenaDNA reaches state-of-the-art (SotA) on 12 of 18 datasets using a model with orders of magnitude less parameters and pretraining data. On the GenomicBenchmarks, HyenaDNA surpasses SotA on 7 of 8 datasets on average by +10 accuracy points. Code at https://github.com/HazyResearch/hyena-dna.},
	urldate = {2025-07-23},
	publisher = {arXiv},
	author = {Nguyen, Eric and Poli, Michael and Faizi, Marjan and Thomas, Armin and Birch-Sykes, Callum and Wornow, Michael and Patel, Aman and Rabideau, Clayton and Massaroli, Stefano and Bengio, Yoshua and Ermon, Stefano and Baccus, Stephen A. and Ré, Chris},
	month = nov,
	year = {2023},
	note = {arXiv:2306.15794 [cs]},
	keywords = {Printed, Important, Podcast, Read},
	file = {Preprint PDF:/Users/meehl.joshua/Zotero/storage/JVEF4BBI/2023-11-14 - Nguyen et al. - HyenaDNA Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution.pdf:application/pdf;Snapshot:/Users/meehl.joshua/Zotero/storage/G59U5Z77/2306.html:text/html},
}

@misc{rakowski_mifm_2025,
	title = {[{MIFM}] {Multiple} instance fine-mapping: predicting causal regulatory variants with a deep sequence model},
	copyright = {© 2025, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	shorttitle = {Multiple instance fine-mapping},
	url = {https://www.medrxiv.org/content/10.1101/2025.06.13.25329551v1},
	doi = {10.1101/2025.06.13.25329551},
	abstract = {Identifying causal genetic variants in a computational manner remains an open problem. Training end-to-end prediction models is not possible without large ground-truth datasets, while results of genome-wide association studies (GWAS) are entangled by linkage disequilibrium (LD), and gene expression datasets do not contain genetic variation at individual-level. Here, we propose Multiple Instance Fine-mapping (MIFM) – a multiple instance learning (MIL) objective to overcome the lack of strong labels by grouping putatively causal variants together based on their LD scores. Using MIFM, we trained a deep classifier on a dataset aggregating over 13, 000 GWAS to predict causal variants based on their underlying DNA sequences. We validated variants prioritized by MIFM by constructing polygenic risk scores which transferred better to different target ancestries. Furthermore, we demonstrated how MIFM can be used to disentangle effect sizes of highly-correlated variants to better fine-map GWAS results.
Author summary Genome-wide association studies have identified tens of thousands genetic variants associated with traits or diseases. However, the majority of identified variants is only spuriously correlated with the phenotype of interest, having no causal effect on it. Instead, these variants are often inherited together with nearby biologically causal variants, thus creating the spurious associations. Fine-mapping, i.e., predicting which variants are causal, is crucial for downstream tasks, such as uncovering the biological mechanisms affecting the phenotype or robustly identifying individuals with high genetic risk of a disease. While most fine-mapping methods are based on the available association statistics or functional annotations of genetic regions, it should be possible to identify causal variants based on their neighboring DNA sequences. However, training a standard machine learning classifier for that task is obstructed by the scarcity of strong, ground-truth labels. Here, we proposed a method to train sequence models predicting variant causality using weakly-labeled data. We trained a model on a large set of associated variants, and demonstrated its utility by improving cross-ancestry predictions of genetic risk, or disentangling the effect sizes of highly correlated variants.},
	language = {en},
	urldate = {2025-07-11},
	publisher = {medRxiv},
	author = {Rakowski, Alexander and Lippert, Christoph},
	month = jun,
	year = {2025},
	note = {0 citations (Crossref/DOI) [2025-10-22]
Pages: 2025.06.13.25329551},
	keywords = {Printed, Podcast, Recall},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/AI64IU6X/2025-06-14 - Rakowski and Lippert - [MIFM] Multiple instance fine-mapping predicting causal regulatory variants with a deep sequence mo.pdf:application/pdf},
}

@article{katzman_deepsurv_2018,
	title = {{DeepSurv}: personalized treatment recommender system using a {Cox} proportional hazards deep neural network},
	volume = {18},
	issn = {1471-2288},
	shorttitle = {{DeepSurv}},
	url = {https://doi.org/10.1186/s12874-018-0482-1},
	doi = {10.1186/s12874-018-0482-1},
	abstract = {Medical practitioners use survival models to explore and understand the relationships between patients’ covariates (e.g. clinical and genetic features) and the effectiveness of various treatment options. Standard survival models like the linear Cox proportional hazards model require extensive feature engineering or prior medical knowledge to model treatment interaction at an individual level. While nonlinear survival methods, such as neural networks and survival forests, can inherently model these high-level interaction terms, they have yet to be shown as effective treatment recommender systems.},
	language = {en},
	number = {1},
	urldate = {2025-12-24},
	journal = {BMC Medical Research Methodology},
	author = {Katzman, Jared L. and Shaham, Uri and Cloninger, Alexander and Bates, Jonathan and Jiang, Tingting and Kluger, Yuval},
	month = feb,
	year = {2018},
	pages = {24},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/56BJGZKJ/2018-02-26 - Katzman et al. - DeepSurv personalized treatment recommender system using a Cox proportional hazards deep neural net.pdf:application/pdf},
}

@article{nagpal_deep_2021,
	title = {Deep {Survival} {Machines}: {Fully} {Parametric} {Survival} {Regression} and {Representation} {Learning} for {Censored} {Data} {With} {Competing} {Risks}},
	volume = {25},
	issn = {2168-2208},
	shorttitle = {Deep {Survival} {Machines}},
	url = {https://ieeexplore.ieee.org/abstract/document/9326348},
	doi = {10.1109/JBHI.2021.3052441},
	abstract = {We describe a new approach to estimating relative risks in time-to-event prediction problems with censored data in a fully parametric manner. Our approach does not require making strong assumptions of constant proportional hazards of the underlying survival distribution, as required by the Cox-proportional hazard model. By jointly learning deep nonlinear representations of the input covariates, we demonstrate the benefits of our approach when used to estimate survival risks through extensive experimentation on multiple real world datasets with different levels of censoring. We further demonstrate advantages of our model in the competing risks scenario. To the best of our knowledge, this is the first work involving fully parametric estimation of survival times with competing risks in the presence of censoring.},
	number = {8},
	urldate = {2025-12-24},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	author = {Nagpal, Chirag and Li, Xinyu and Dubrawski, Artur},
	month = aug,
	year = {2021},
	pages = {3163--3175},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/ESP7Z56D/2021-08 - Nagpal et al. - Deep Survival Machines Fully Parametric Survival Regression and Representation Learning for Censore.pdf:application/pdf},
}

@article{tipirneni_self-supervised_2022,
	title = {Self-{Supervised} {Transformer} for {Sparse} and {Irregularly} {Sampled} {Multivariate} {Clinical} {Time}-{Series}},
	volume = {16},
	issn = {1556-4681},
	url = {https://doi.org/10.1145/3516367},
	doi = {10.1145/3516367},
	abstract = {Multivariate time-series data are frequently observed in critical care settings and are typically characterized by sparsity (missing information) and irregular time intervals. Existing approaches for learning representations in this domain handle these challenges by either aggregation or imputation of values, which in-turn suppresses the fine-grained information and adds undesirable noise/overhead into the machine learning model. To tackle this problem, we propose a Self-supervised Transformer for Time-Series (STraTS) model, which overcomes these pitfalls by treating time-series as a set of observation triplets instead of using the standard dense matrix representation. It employs a novel Continuous Value Embedding technique to encode continuous time and variable values without the need for discretization. It is composed of a Transformer component with multi-head attention layers, which enable it to learn contextual triplet embeddings while avoiding the problems of recurrence and vanishing gradients that occur in recurrent architectures. In addition, to tackle the problem of limited availability of labeled data (which is typically observed in many healthcare applications), STraTS utilizes self-supervision by leveraging unlabeled data to learn better representations by using time-series forecasting as an auxiliary proxy task. Experiments on real-world multivariate clinical time-series benchmark datasets demonstrate that STraTS has better prediction performance than state-of-the-art methods for mortality prediction, especially when labeled data is limited. Finally, we also present an interpretable version of STraTS, which can identify important measurements in the time-series data. Our data preprocessing and model implementation codes are available at .},
	number = {6},
	urldate = {2025-12-24},
	journal = {ACM Trans. Knowl. Discov. Data},
	author = {Tipirneni, Sindhu and Reddy, Chandan K.},
	month = jul,
	year = {2022},
	pages = {105:1--105:17},
	file = {Full Text:/Users/meehl.joshua/Zotero/storage/J2HPFJS5/July 30, 2022 - Tipirneni and Reddy - Self-Supervised Transformer for Sparse and Irregularly Sampled Multivariate Clinical Time-Series.pdf:application/pdf},
}

@article{xu_improving_2025,
	title = {Improving polygenic risk prediction performance by integrating electronic health records through phenotype embedding},
	volume = {112},
	issn = {0002-9297},
	url = {https://www.sciencedirect.com/science/article/pii/S0002929725004318},
	doi = {10.1016/j.ajhg.2025.11.006},
	abstract = {Large-scale biobanks provide comprehensive electronic health records (EHRs) that capture detailed clinical phenotypes, potentially enhancing disease prediction. However, traditional polygenic risk score (PRS) methods rely on simplified phenotype definitions or predefined trait sets, limiting their ability to represent the complex structures embedded within EHRs. To address this gap, we introduce EHR-embedding-enhanced PRS (EEPRS), leveraging phenotype embeddings derived from EHRs to improve PRSs using only genome-wide association study (GWAS) summary statistics. Employing embedding methods such as Word2Vec and GPT, we conducted EHR-embedding-based GWASs and identified a cardiovascular cluster via hierarchical clustering of genetic correlations. Across 41 traits in the UK Biobank, EEPRS consistently outperformed single-trait PRSs, particularly within this cluster. PRS-based phenome-wide association studies further demonstrated robust associations between EHR-embedding-based PRS and circulatory system diseases. We then developed EEPRS\_optimal, a data-adaptive method that uses cross-validation to select the best embedding, yielding additional improvements. We also developed MTAG\_EEPRS for multi-trait PRSs, which further improved prediction accuracy compared to single-trait PRSs and MTAG\_PRS. Finally, we validated the benefits of EEPRS in the All of Us cohort for seven selected diseases. Overall, EEPRS represents a robust and interpretable framework, enhancing single-trait and multi-trait PRSs by integrating EHR embeddings.},
	number = {12},
	urldate = {2025-12-24},
	journal = {The American Journal of Human Genetics},
	author = {Xu, Leqi and Zheng, Wangjie and Hu, Jiaqi and Lin, Yingxin and Zhao, Jia and Wang, Gefei and Liu, Tianyu and Zhao, Hongyu},
	month = dec,
	year = {2025},
	pages = {3030--3045},
	file = {ScienceDirect Full Text PDF:/Users/meehl.joshua/Zotero/storage/4C4SFAYW/2025-12-04 - Xu et al. - Improving polygenic risk prediction performance by integrating electronic health records through phe.pdf:application/pdf;ScienceDirect Snapshot:/Users/meehl.joshua/Zotero/storage/E8ZYWZR9/S0002929725004318.html:text/html},
}