@article{ji_dnabert_2021,
	title = {{DNABERT}: pre-trained {Bidirectional} {Encoder} {Representations} from {Transformers} model for {DNA}-language in genome},
	volume = {37},
	issn = {1367-4803},
	shorttitle = {{DNABERT}},
	url = {https://doi.org/10.1093/bioinformatics/btab083},
	doi = {10.1093/bioinformatics/btab083},
	abstract = {Deciphering the language of non-coding DNA is one of the fundamental problems in genome research. Gene regulatory code is highly complex due to the existence of polysemy and distant semantic relationship, which previous informatics methods often fail to capture especially in data-scarce scenarios.To address this challenge, we developed a novel pre-trained bidirectional encoder representation, named DNABERT, to capture global and transferrable understanding of genomic DNA sequences based on up and downstream nucleotide contexts. We compared DNABERT to the most widely used programs for genome-wide regulatory elements prediction and demonstrate its ease of use, accuracy and efficiency. We show that the single pre-trained transformers model can simultaneously achieve state-of-the-art performance on prediction of promoters, splice sites and transcription factor binding sites, after easy fine-tuning using small task-specific labeled data. Further, DNABERT enables direct visualization of nucleotide-level importance and semantic relationship within input sequences for better interpretability and accurate identification of conserved sequence motifs and functional genetic variant candidates. Finally, we demonstrate that pre-trained DNABERT with human genome can even be readily applied to other organisms with exceptional performance. We anticipate that the pre-trained DNABERT model can be fined tuned to many other sequence analyses tasks.The source code, pretrained and finetuned model for DNABERT are available at GitHub (https://github.com/jerryji1993/DNABERT).Supplementary data are available at Bioinformatics online.},
	number = {15},
	urldate = {2025-08-31},
	journal = {Bioinformatics},
	author = {Ji, Yanrong and Zhou, Zhihan and Liu, Han and Davuluri, Ramana V},
	month = aug,
	year = {2021},
	note = {802 citations (Crossref/DOI) [2025-10-22]},
	pages = {2112--2120},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/VKSTMFPQ/2021-08-09 - Ji et al. - DNABERT pre-trained Bidirectional Encoder Representations from Transformers model for DNA-language.pdf:application/pdf;Snapshot:/Users/meehl.joshua/Zotero/storage/UBBEDFL5/btab083.html:text/html},
}

@misc{zhou_dnabert-2_2024,
	title = {{DNABERT}-2: {Efficient} {Foundation} {Model} and {Benchmark} {For} {Multi}-{Species} {Genome}},
	shorttitle = {{DNABERT}-2},
	url = {http://arxiv.org/abs/2306.15006},
	doi = {10.48550/arXiv.2306.15006},
	abstract = {Decoding the linguistic intricacies of the genome is a crucial problem in biology, and pre-trained foundational models such as DNABERT and Nucleotide Transformer have made significant strides in this area. Existing works have largely hinged on k-mer, fixed-length permutations of A, T, C, and G, as the token of the genome language due to its simplicity. However, we argue that the computation and sample inefficiencies introduced by k-mer tokenization are primary obstacles in developing large genome foundational models. We provide conceptual and empirical insights into genome tokenization, building on which we propose to replace k-mer tokenization with Byte Pair Encoding (BPE), a statistics-based data compression algorithm that constructs tokens by iteratively merging the most frequent co-occurring genome segment in the corpus. We demonstrate that BPE not only overcomes the limitations of k-mer tokenization but also benefits from the computational efficiency of non-overlapping tokenization. Based on these insights, we introduce DNABERT-2, a refined genome foundation model that adapts an efficient tokenizer and employs multiple strategies to overcome input length constraints, reduce time and memory expenditure, and enhance model capability. Furthermore, we identify the absence of a comprehensive and standardized benchmark for genome understanding as another significant impediment to fair comparative analysis. In response, we propose the Genome Understanding Evaluation (GUE), a comprehensive multi-species genome classification dataset that amalgamates \$36\$ distinct datasets across \$9\$ tasks, with input lengths ranging from \$70\$ to \$10000\$. Through comprehensive experiments on the GUE benchmark, we demonstrate that DNABERT-2 achieves comparable performance to the state-of-the-art model with \$21 {\textbackslash}times\$ fewer parameters and approximately \$92 {\textbackslash}times\$ less GPU time in pre-training.},
	urldate = {2025-05-28},
	publisher = {arXiv},
	author = {Zhou, Zhihan and Ji, Yanrong and Li, Weijian and Dutta, Pratik and Davuluri, Ramana and Liu, Han},
	month = mar,
	year = {2024},
	note = {arXiv:2306.15006 [q-bio]},
	keywords = {Printed, Important, Podcast, Read},
	file = {Preprint PDF:/Users/meehl.joshua/Zotero/storage/2KZP5KPQ/2024-03-18 - Zhou et al. - DNABERT-2 Efficient Foundation Model and Benchmark For Multi-Species Genome.pdf:application/pdf;Snapshot:/Users/meehl.joshua/Zotero/storage/KUYT79IL/2306.html:text/html},
}

@article{dalla-torre_nucleotide_2023,
	title = {Nucleotide {Transformer}: building and evaluating robust foundation models for human genomics},
	volume = {22},
	copyright = {2024 The Author(s)},
	issn = {1548-7105},
	shorttitle = {Nucleotide {Transformer}},
	url = {https://www.nature.com/articles/s41592-024-02523-z},
	doi = {10.1038/s41592-024-02523-z},
	abstract = {The prediction of molecular phenotypes from DNA sequences remains a longstanding challenge in genomics, often driven by limited annotated data and the inability to transfer learnings between tasks. Here, we present an extensive study of foundation models pre-trained on DNA sequences, named Nucleotide Transformer, ranging from 50 million up to 2.5 billion parameters and integrating information from 3,202 human genomes and 850 genomes from diverse species. These transformer models yield context-specific representations of nucleotide sequences, which allow for accurate predictions even in low-data settings. We show that the developed models can be fine-tuned at low cost to solve a variety of genomics applications. Despite no supervision, the models learned to focus attention on key genomic elements and can be used to improve the prioritization of genetic variants. The training and application of foundational models in genomics provides a widely applicable approach for accurate molecular phenotype prediction from DNA sequence.},
	language = {en},
	number = {2},
	urldate = {2025-04-16},
	journal = {Nature Methods},
	author = {Dalla-Torre, Hugo and Gonzalez, Liam and Mendoza-Revilla, Javier and Lopez Carranza, Nicolas and Grzywaczewski, Adam Henryk and Oteri, Francesco and Dallago, Christian and Trop, Evan and de Almeida, Bernardo P. and Sirelkhatim, Hassan and Richard, Guillaume and Skwark, Marcin and Beguir, Karim and Lopez, Marie and Pierrot, Thomas},
	month = jan,
	year = {2023},
	note = {123 citations (Crossref/DOI) [2025-10-22]
Publisher: Nature Publishing Group},
	keywords = {Printed, Important, Podcast, Read},
	pages = {287--297},
	file = {[Preprint] Dalla-Torre et al. - 2023 - Nucleotide Transformer building and evaluating robust foundation models for human genomics:/Users/meehl.joshua/Zotero/storage/METWGZEF/2023-01-15 - Dalla-Torre et al. - Nucleotide Transformer building and evaluating robust foundation models for human genomics.pdf:application/pdf;Full Text PDF:/Users/meehl.joshua/Zotero/storage/K28P6JFS/2023-01-15 - Dalla-Torre et al. - Nucleotide Transformer building and evaluating robust foundation models for human genomics.pdf:application/pdf},
}

@misc{nguyen_hyenadna_2023,
	title = {{HyenaDNA}: {Long}-{Range} {Genomic} {Sequence} {Modeling} at {Single} {Nucleotide} {Resolution}},
	shorttitle = {{HyenaDNA}},
	url = {http://arxiv.org/abs/2306.15794},
	doi = {10.48550/arXiv.2306.15794},
	abstract = {Genomic (DNA) sequences encode an enormous amount of information for gene regulation and protein synthesis. Similar to natural language models, researchers have proposed foundation models in genomics to learn generalizable features from unlabeled genome data that can then be fine-tuned for downstream tasks such as identifying regulatory elements. Due to the quadratic scaling of attention, previous Transformer-based genomic models have used 512 to 4k tokens as context ({\textless}0.001\% of the human genome), significantly limiting the modeling of long-range interactions in DNA. In addition, these methods rely on tokenizers or fixed k-mers to aggregate meaningful DNA units, losing single nucleotide resolution where subtle genetic variations can completely alter protein function via single nucleotide polymorphisms (SNPs). Recently, Hyena, a large language model based on implicit convolutions was shown to match attention in quality while allowing longer context lengths and lower time complexity. Leveraging Hyena's new long-range capabilities, we present HyenaDNA, a genomic foundation model pretrained on the human reference genome with context lengths of up to 1 million tokens at the single nucleotide-level - an up to 500x increase over previous dense attention-based models. HyenaDNA scales sub-quadratically in sequence length (training up to 160x faster than Transformer), uses single nucleotide tokens, and has full global context at each layer. We explore what longer context enables - including the first use of in-context learning in genomics. On fine-tuned benchmarks from the Nucleotide Transformer, HyenaDNA reaches state-of-the-art (SotA) on 12 of 18 datasets using a model with orders of magnitude less parameters and pretraining data. On the GenomicBenchmarks, HyenaDNA surpasses SotA on 7 of 8 datasets on average by +10 accuracy points. Code at https://github.com/HazyResearch/hyena-dna.},
	urldate = {2025-07-23},
	publisher = {arXiv},
	author = {Nguyen, Eric and Poli, Michael and Faizi, Marjan and Thomas, Armin and Birch-Sykes, Callum and Wornow, Michael and Patel, Aman and Rabideau, Clayton and Massaroli, Stefano and Bengio, Yoshua and Ermon, Stefano and Baccus, Stephen A. and Ré, Chris},
	month = nov,
	year = {2023},
	note = {arXiv:2306.15794 [cs]},
	keywords = {Printed, Important, Podcast, Read},
	file = {Preprint PDF:/Users/meehl.joshua/Zotero/storage/JVEF4BBI/2023-11-14 - Nguyen et al. - HyenaDNA Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution.pdf:application/pdf;Snapshot:/Users/meehl.joshua/Zotero/storage/G59U5Z77/2306.html:text/html},
}

@misc{schiff_caduceus_2024,
	title = {Caduceus: {Bi}-{Directional} {Equivariant} {Long}-{Range} {DNA} {Sequence} {Modeling}},
	shorttitle = {Caduceus},
	url = {http://arxiv.org/abs/2403.03234},
	doi = {10.48550/arXiv.2403.03234},
	abstract = {Large-scale sequence modeling has sparked rapid advances that now extend into biology and genomics. However, modeling genomic sequences introduces challenges such as the need to model long-range token interactions, the effects of upstream and downstream regions of the genome, and the reverse complementarity (RC) of DNA. Here, we propose an architecture motivated by these challenges that builds off the long-range Mamba block, and extends it to a BiMamba component that supports bi-directionality, and to a MambaDNA block that additionally supports RC equivariance. We use MambaDNA as the basis of Caduceus, the first family of RC equivariant bi-directional long-range DNA language models, and we introduce pre-training and fine-tuning strategies that yield Caduceus DNA foundation models. Caduceus outperforms previous long-range models on downstream benchmarks; on a challenging long-range variant effect prediction task, Caduceus exceeds the performance of 10x larger models that do not leverage bi-directionality or equivariance.},
	urldate = {2025-07-23},
	publisher = {arXiv},
	author = {Schiff, Yair and Kao, Chia-Hsiang and Gokaslan, Aaron and Dao, Tri and Gu, Albert and Kuleshov, Volodymyr},
	month = jun,
	year = {2024},
	note = {arXiv:2403.03234 [q-bio]},
	keywords = {Printed, Podcast, Read},
	file = {Preprint PDF:/Users/meehl.joshua/Zotero/storage/PN2AQVMU/2024-06-05 - Schiff et al. - Caduceus Bi-Directional Equivariant Long-Range DNA Sequence Modeling.pdf:application/pdf;Snapshot:/Users/meehl.joshua/Zotero/storage/YIPW7H9E/2403.html:text/html},
}

@article{sanabria_grover_2024,
	title = {[{GROVER}] {DNA} language model {GROVER} learns sequence context in the human genome},
	volume = {6},
	copyright = {2024 The Author(s)},
	issn = {2522-5839},
	url = {https://www.nature.com/articles/s42256-024-00872-0},
	doi = {10.1038/s42256-024-00872-0},
	abstract = {Deep-learning models that learn a sense of language on DNA have achieved a high level of performance on genome biological tasks. Genome sequences follow rules similar to natural language but are distinct in the absence of a concept of words. We established byte-pair encoding on the human genome and trained a foundation language model called GROVER (Genome Rules Obtained Via Extracted Representations) with the vocabulary selected via a custom task, next-k-mer prediction. The defined dictionary of tokens in the human genome carries best the information content for GROVER. Analysing learned representations, we observed that trained token embeddings primarily encode information related to frequency, sequence content and length. Some tokens are primarily localized in repeats, whereas the majority widely distribute over the genome. GROVER also learns context and lexical ambiguity. Average trained embeddings of genomic regions relate to functional genomics annotation and thus indicate learning of these structures purely from the contextual relationships of tokens. This highlights the extent of information content encoded by the sequence that can be grasped by GROVER. On fine-tuning tasks addressing genome biology with questions of genome element identification and protein–DNA binding, GROVER exceeds other models’ performance. GROVER learns sequence context, a sense for structure and language rules. Extracting this knowledge can be used to compose a grammar book for the code of life.},
	language = {en},
	number = {8},
	urldate = {2025-07-25},
	journal = {Nature Machine Intelligence},
	author = {Sanabria, Melissa and Hirsch, Jonas and Joubert, Pierre M. and Poetsch, Anna R.},
	month = jul,
	year = {2024},
	note = {47 citations (Crossref/DOI) [2025-10-22]
Publisher: Nature Publishing Group},
	keywords = {Printed},
	pages = {911--923},
	file = {2024-07-23 - Sanabria et al. - [Preprint][GROVER] DNA language model GROVER learns sequence context in the human genome:/Users/meehl.joshua/Zotero/storage/WLAJANB6/2024-07-23 - Sanabria et al. - [Preprint][GROVER] DNA language model GROVER learns sequence context in the human genome.pdf:application/pdf;Full Text PDF:/Users/meehl.joshua/Zotero/storage/SNYYQVLT/2024-07-23 - Sanabria et al. - [GROVER] DNA language model GROVER learns sequence context in the human genome.pdf:application/pdf},
}

@misc{medvedev_biotoken_2025,
	title = {{BioToken} and {BioFM} – {Biologically}-{Informed} {Tokenization} {Enables} {Accurate} and {Efficient} {Genomic} {Foundation} {Models}},
	copyright = {© 2025, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2025.03.27.645711v1},
	doi = {10.1101/2025.03.27.645711},
	abstract = {Genomic variation underlies human phenotypic diversity, disease susceptibility, and evolutionary adaptation. Although large-scale genomic sequencing has transformed our ability to map genetic variation, accurately modeling and interpreting this data remains challenging due to fundamental limitations in existing genomic foundation models (GFMs). Current genomic models typically treat DNA simplistically as linear textual sequences, overlooking critical biological context, such as genomic structural annotations, regulatory elements, and functional contexts central to genomic interpretation. As a result, these models are prone to positional memorization of common sequences, severely limiting their generalization to biologically meaningful tasks. Here, we introduce BioToken, a modular and extendable tokenization framework designed to encode genomic variants and biologically relevant structural annotations directly into genomic representations. By utilizing intrinsic inductive biases, BioToken facilitates meaningful representation learning and generalization across diverse molecular phenotypes, such as gene expression, alternative splicing, and variant pathogenicity prediction. Built on BioToken, our genomic foundation model, BioFM, achieves competitive or superior results relative to specialized models (e.g., Enformer, SpliceTransformer) across a comprehensive suite of genomic benchmarks, including noncoding pathogenicity, expression modulation, sQTL prediction, and long-range genomic interactions. Notably, BioFM achieves state-of-the-art performance with significantly fewer parameters (265M), substantially reducing training costs and computational requirements. Our findings high-light the substantial advantages of integrating biologically-informed inductive biases into genomic foundation modeling, providing a robust and accessible path forward in genomics. We provide our code and model checkpoints to support further research in this direction.},
	language = {en},
	urldate = {2025-05-27},
	publisher = {bioRxiv},
	author = {Medvedev, Aleksandr and Viswanathan, Karthik and Kanithi, Praveenkumar and Vishniakov, Kirill and Munjal, Prateek and Christophe, Clément and Pimentel, Marco AF and Rajan, Ronnie and Khan, Shadab},
	month = apr,
	year = {2025},
	note = {1 citations (Crossref/DOI) [2025-10-22]
Pages: 2025.03.27.645711
Section: New Results},
	keywords = {Printed, Podcast},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/XZBQLGZE/2025-04-01 - Medvedev et al. - BioToken and BioFM – Biologically-Informed Tokenization Enables Accurate and Efficient Genomic Found.pdf:application/pdf},
}

@article{rives_esm_2021,
	title = {[{ESM}-1b] {Biological} structure and function emerge from scaling unsupervised learning to 250 million protein sequences},
	volume = {118},
	issn = {1091-6490},
	doi = {10.1073/pnas.2016239118},
	abstract = {In the field of artificial intelligence, a combination of scale in data and model capacity enabled by unsupervised learning has led to major advances in representation learning and statistical generation. In the life sciences, the anticipated growth of sequencing promises unprecedented data on natural sequence diversity. Protein language modeling at the scale of evolution is a logical step toward predictive and generative artificial intelligence for biology. To this end, we use unsupervised learning to train a deep contextual language model on 86 billion amino acids across 250 million protein sequences spanning evolutionary diversity. The resulting model contains information about biological properties in its representations. The representations are learned from sequence data alone. The learned representation space has a multiscale organization reflecting structure from the level of biochemical properties of amino acids to remote homology of proteins. Information about secondary and tertiary structure is encoded in the representations and can be identified by linear projections. Representation learning produces features that generalize across a range of applications, enabling state-of-the-art supervised prediction of mutational effect and secondary structure and improving state-of-the-art features for long-range contact prediction.},
	language = {eng},
	number = {15},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Rives, Alexander and Meier, Joshua and Sercu, Tom and Goyal, Siddharth and Lin, Zeming and Liu, Jason and Guo, Demi and Ott, Myle and Zitnick, C. Lawrence and Ma, Jerry and Fergus, Rob},
	month = apr,
	year = {2021},
	pmid = {33876751},
	pmcid = {PMC8053943},
	note = {2208 citations (Crossref/DOI) [2025-10-22]},
	pages = {e2016239118},
	file = {Rives et al. - 2021 - Biological structure and function emerge from scal-Supplement.pdf:/Users/meehl.joshua/Zotero/storage/V5K3TREP/2021-04-13 - Rives et al. - [ESM-1b] Biological structure and function emerge from scaling unsupervised learning to 250 million.pdf:application/pdf;Rives et al. - 2021 - Biological structure and function emerge from scal.pdf:/Users/meehl.joshua/Zotero/storage/45JE6CKI/2021-04-13 - Rives et al. - [ESM-1b] Biological structure and function emerge from scaling unsupervised learning to 250 million.pdf:application/pdf},
}

@misc{lin_esm-2_2022,
	title = {[{ESM}-2] {Language} models of protein sequences at the scale of evolution enable accurate structure prediction},
	copyright = {© 2022, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2022.07.20.500902v1},
	doi = {10.1101/2022.07.20.500902},
	abstract = {Large language models have recently been shown to develop emergent capabilities with scale, going beyond simple pattern matching to perform higher level reasoning and generate lifelike images and text. While language models trained on protein sequences have been studied at a smaller scale, little is known about what they learn about biology as they are scaled up. In this work we train models up to 15 billion parameters, the largest language models of proteins to be evaluated to date. We find that as models are scaled they learn information enabling the prediction of the three-dimensional structure of a protein at the resolution of individual atoms. We present ESMFold for high accuracy end-to-end atomic level structure prediction directly from the individual sequence of a protein. ESMFold has similar accuracy to AlphaFold2 and RoseTTAFold for sequences with low perplexity that are well understood by the language model. ESMFold inference is an order of magnitude faster than AlphaFold2, enabling exploration of the structural space of metagenomic proteins in practical timescales.},
	language = {en},
	urldate = {2022-12-20},
	publisher = {bioRxiv},
	author = {Lin, Zeming and Akin, Halil and Rao, Roshan and Hie, Brian and Zhu, Zhongkai and Lu, Wenting and Costa, Allan dos Santos and Fazel-Zarandi, Maryam and Sercu, Tom and Candido, Sal and Rives, Alexander},
	month = jul,
	year = {2022},
	note = {273 citations (Crossref/DOI) [2025-10-22]
Pages: 2022.07.20.500902
Section: New Results},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/B28E6SXM/2022-07-21 - Lin et al. - [ESM-2] Language models of protein sequences at the scale of evolution enable accurate structure pre.pdf:application/pdf},
}

@article{brandes_genome-wide_2023,
	title = {Genome-wide prediction of disease variant effects with a deep protein language model},
	volume = {55},
	copyright = {2023 The Author(s)},
	issn = {1546-1718},
	url = {https://www.nature.com/articles/s41588-023-01465-0},
	doi = {10.1038/s41588-023-01465-0},
	abstract = {Predicting the effects of coding variants is a major challenge. While recent deep-learning models have improved variant effect prediction accuracy, they cannot analyze all coding variants due to dependency on close homologs or software limitations. Here we developed a workflow using ESM1b, a 650-million-parameter protein language model, to predict all {\textasciitilde}450 million possible missense variant effects in the human genome, and made all predictions available on a web portal. ESM1b outperformed existing methods in classifying {\textasciitilde}150,000 ClinVar/HGMD missense variants as pathogenic or benign and predicting measurements across 28 deep mutational scan datasets. We further annotated {\textasciitilde}2 million variants as damaging only in specific protein isoforms, demonstrating the importance of considering all isoforms when predicting variant effects. Our approach also generalizes to more complex coding variants such as in-frame indels and stop-gains. Together, these results establish protein language models as an effective, accurate and general approach to predicting variant effects.},
	language = {en},
	number = {9},
	urldate = {2025-08-07},
	journal = {Nature Genetics},
	author = {Brandes, Nadav and Goldman, Grant and Wang, Charlotte H. and Ye, Chun Jimmie and Ntranos, Vasilis},
	month = aug,
	year = {2023},
	note = {312 citations (Crossref/DOI) [2025-10-22]
Publisher: Nature Publishing Group},
	keywords = {Printed, Read},
	pages = {1512--1522},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/8TS597B9/2023-09 - Brandes et al. - Genome-wide prediction of disease variant effects with a deep protein language model.pdf:application/pdf},
}

@article{zhou_deepsea_2015,
	title = {[{DeepSEA}] {Predicting} effects of noncoding variants with deep learning–based sequence model},
	volume = {12},
	copyright = {2015 Springer Nature America, Inc.},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/nmeth.3547},
	doi = {10.1038/nmeth.3547},
	abstract = {DeepSEA, a deep-learning algorithm trained on large-scale chromatin-profiling data, predicts chromatin effects from sequence alone, has single-nucleotide sensitivity and can predict effects of noncoding variants.},
	language = {en},
	number = {10},
	urldate = {2025-08-12},
	journal = {Nature Methods},
	author = {Zhou, Jian and Troyanskaya, Olga G.},
	month = aug,
	year = {2015},
	note = {2031 citations (Crossref/DOI) [2025-10-22]
Publisher: Nature Publishing Group},
	pages = {931--934},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/DS72YP6N/2015-10 - Zhou and Troyanskaya - [DeepSEA] Predicting effects of noncoding variants with deep learning–based sequence model.pdf:application/pdf},
}

@article{zhou_expecto_2018,
	title = {[{Expecto}] {Deep} learning sequence-based ab initio prediction of variant effects on expression and disease risk},
	volume = {50},
	copyright = {2018 The Author(s)},
	issn = {1546-1718},
	url = {https://www.nature.com/articles/s41588-018-0160-6},
	doi = {10.1038/s41588-018-0160-6},
	abstract = {Key challenges for human genetics, precision medicine and evolutionary biology include deciphering the regulatory code of gene expression and understanding the transcriptional effects of genome variation. However, this is extremely difficult because of the enormous scale of the noncoding mutation space. We developed a deep learning–based framework, ExPecto, that can accurately predict, ab initio from a DNA sequence, the tissue-specific transcriptional effects of mutations, including those that are rare or that have not been observed. We prioritized causal variants within disease- or trait-associated loci from all publicly available genome-wide association studies and experimentally validated predictions for four immune-related diseases. By exploiting the scalability of ExPecto, we characterized the regulatory mutation space for human RNA polymerase II–transcribed genes by in silico saturation mutagenesis and profiled {\textgreater} 140 million promoter-proximal mutations. This enables probing of evolutionary constraints on gene expression and ab initio prediction of mutation disease effects, making ExPecto an end-to-end computational framework for the in silico prediction of expression and disease risk.},
	language = {en},
	number = {8},
	urldate = {2025-07-25},
	journal = {Nature Genetics},
	author = {Zhou, Jian and Theesfeld, Chandra L. and Yao, Kevin and Chen, Kathleen M. and Wong, Aaron K. and Troyanskaya, Olga G.},
	month = jul,
	year = {2018},
	note = {420 citations (Crossref/DOI) [2025-10-22]
Publisher: Nature Publishing Group},
	keywords = {Printed, Read, Recall},
	pages = {1171--1179},
	file = {2018-07-16 - Zhou et al. - [DeepSEA Beluga] Deep learning sequence-based ab initio prediction of variant effects on expression:/Users/meehl.joshua/Zotero/storage/GDYBADGZ/2018-07-16 - Zhou et al. - [DeepSEA Beluga] Deep learning sequence-based ab initio prediction of variant effects on expression.pdf:application/pdf},
}

@article{chen_deepsea_2022,
	title = {[{DeepSEA} {Sei}] {A} sequence-based global map of regulatory activity for deciphering human genetics},
	volume = {54},
	copyright = {2022 The Author(s)},
	issn = {1546-1718},
	url = {https://www.nature.com/articles/s41588-022-01102-2},
	doi = {10.1038/s41588-022-01102-2},
	abstract = {Epigenomic profiling has enabled large-scale identification of regulatory elements, yet we still lack a systematic mapping from any sequence or variant to regulatory activities. We address this challenge with Sei, a framework for integrating human genetics data with sequence information to discover the regulatory basis of traits and diseases. Sei learns a vocabulary of regulatory activities, called sequence classes, using a deep learning model that predicts 21,907 chromatin profiles across {\textgreater}1,300 cell lines and tissues. Sequence classes provide a global classification and quantification of sequence and variant effects based on diverse regulatory activities, such as cell type-specific enhancer functions. These predictions are supported by tissue-specific expression, expression quantitative trait loci and evolutionary constraint data. Furthermore, sequence classes enable characterization of the tissue-specific, regulatory architecture of complex traits and generate mechanistic hypotheses for individual regulatory pathogenic mutations. We provide Sei as a resource to elucidate the regulatory basis of human health and disease.},
	language = {en},
	number = {7},
	urldate = {2025-07-23},
	journal = {Nature Genetics},
	author = {Chen, Kathleen M. and Wong, Aaron K. and Troyanskaya, Olga G. and Zhou, Jian},
	month = jul,
	year = {2022},
	note = {194 citations (Crossref/DOI) [2025-10-22]
Publisher: Nature Publishing Group},
	keywords = {Printed, Read},
	pages = {940--949},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/Y5MUGXGK/2022-07-11 - Chen et al. - [DeepSEA Sei] A sequence-based global map of regulatory activity for deciphering human genetics.pdf:application/pdf},
}

@article{avsec_enformer_2021,
	title = {[{Enformer}] {Effective} gene expression prediction from sequence by integrating long-range interactions},
	volume = {18},
	url = {https://consensus.app/papers/effective-gene-expression-prediction-from-sequence-by-avsec-agarwal/6afb944129f35bad916e6f4a889c07cb/},
	doi = {10.1038/s41592-021-01252-x},
	abstract = {The next phase of genome biology research requires understanding how DNA sequence encodes phenotypes, from the molecular to organismal levels. How noncoding DNA determines gene expression in different cell types is a major unsolved problem, and critical downstream applications in human genetics depend on improved solutions. Here, we report substantially improved gene expression prediction accuracy from DNA sequence through the use of a new deep learning architecture called Enformer that is able to integrate long-range interactions (up to 100 kb away) in the genome. This improvement yielded more accurate variant effect predictions on gene expression for both natural genetic variants and saturation mutagenesis measured by massively parallel reporter assays. Notably, Enformer outperformed the best team on the critical assessment of genome interpretation (CAGI5) challenge for noncoding variant interpretation with no additional training. Furthermore, Enformer learned to predict promoter-enhancer interactions directly from DNA sequence competitively with methods that take direct experimental data as input. We expect that these advances will enable more effective fine-mapping of growing human disease associations to cell-type-specific gene regulatory mechanisms and provide a framework to interpret cis-regulatory evolution. To foster these downstream applications, we have made the pre-trained Enformer model openly available, and provide pre-computed effect predictions for all common variants in the 1000 Genomes dataset. One-sentence summary Improved noncoding variant effect prediction and candidate enhancer prioritization from a more accurate sequence to expression model driven by extended long-range interaction modelling.},
	urldate = {2024-12-25},
	journal = {Nature Methods},
	author = {Avsec, Žiga and Agarwal, Vikram and Visentin, D. and Ledsam, J. and Grabska-Barwinska, A. and Taylor, Kyle R. and Assael, Yannis and Jumper, J. and Kohli, Pushmeet and Kelley, David R.},
	month = oct,
	year = {2021},
	note = {846 citations (Semantic Scholar/DOI) [2025-10-22]
875 citations (Crossref/DOI) [2025-10-22]},
	keywords = {Printed, Podcast, Read},
	pages = {1196--1203},
	file = {41592_2021_1252_MOESM1_ESM:/Users/meehl.joshua/Zotero/storage/7PUC6VKT/41592_2021_1252_MOESM1_ESM.pdf:application/pdf;Full Text:/Users/meehl.joshua/Zotero/storage/WTX3AUV5/2021-10-04 - Avsec et al. - [Enformer] Effective gene expression prediction from sequence by integrating long-range interactions.pdf:application/pdf;Snapshot:/Users/meehl.joshua/Zotero/storage/JWYN5S8L/6afb944129f35bad916e6f4a889c07cb.html:text/html},
}

@article{kelley_basenji_2018,
	title = {[{Basenji2}] {Sequential} regulatory activity prediction across chromosomes with convolutional neural networks},
	volume = {28},
	issn = {1088-9051, 1549-5469},
	url = {http://genome.cshlp.org/content/28/5/739},
	doi = {10.1101/gr.227819.117},
	abstract = {Models for predicting phenotypic outcomes from genotypes have important applications to understanding genomic function and improving human health. Here, we develop a machine-learning system to predict cell-type–specific epigenetic and transcriptional profiles in large mammalian genomes from DNA sequence alone. By use of convolutional neural networks, this system identifies promoters and distal regulatory elements and synthesizes their content to make effective gene expression predictions. We show that model predictions for the influence of genomic variants on gene expression align well to causal variants underlying eQTLs in human populations and can be useful for generating mechanistic hypotheses to enable fine mapping of disease loci.},
	language = {en},
	number = {5},
	urldate = {2025-08-31},
	journal = {Genome Research},
	author = {Kelley, David R. and Reshef, Yakir A. and Bileschi, Maxwell and Belanger, David and McLean, Cory Y. and Snoek, Jasper},
	month = may,
	year = {2018},
	pmid = {29588361},
	note = {439 citations (Crossref/DOI) [2025-10-22]
Company: Cold Spring Harbor Laboratory Press
Distributor: Cold Spring Harbor Laboratory Press
Institution: Cold Spring Harbor Laboratory Press
Label: Cold Spring Harbor Laboratory Press
Publisher: Cold Spring Harbor Lab},
	pages = {739--750},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/3ARI6TG2/05012018 - Kelley et al. - Sequential regulatory activity prediction across chromosomes with convolutional neural networks.pdf:application/pdf},
}

@article{kelley_basenji2_2020,
	title = {[{Basenji2}] {Cross}-species regulatory sequence activity prediction},
	volume = {16},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008050},
	doi = {10.1371/journal.pcbi.1008050},
	abstract = {Machine learning algorithms trained to predict the regulatory activity of nucleic acid sequences have revealed principles of gene regulation and guided genetic variation analysis. While the human genome has been extensively annotated and studied, model organisms have been less explored. Model organism genomes offer both additional training sequences and unique annotations describing tissue and cell states unavailable in humans. Here, we develop a strategy to train deep convolutional neural networks simultaneously on multiple genomes and apply it to learn sequence predictors for large compendia of human and mouse data. Training on both genomes improves gene expression prediction accuracy on held out and variant sequences. We further demonstrate a novel and powerful approach to apply mouse regulatory models to analyze human genetic variants associated with molecular phenotypes and disease. Together these techniques unleash thousands of non-human epigenetic and transcriptional profiles toward more effective investigation of how gene regulation affects human disease.},
	language = {en},
	number = {7},
	urldate = {2025-12-15},
	journal = {PLOS Computational Biology},
	author = {Kelley, David R.},
	month = jul,
	year = {2020},
	note = {Publisher: Public Library of Science},
	pages = {e1008050},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/PRY99MKS/Jul 20, 2020 - Kelley - Cross-species regulatory sequence activity prediction.pdf:application/pdf},
}

@article{linder_borzoi_2025,
	title = {[{Borzoi}] {Predicting} {RNA}-seq coverage from {DNA} sequence as a unifying model of gene regulation},
	volume = {57},
	copyright = {2025 The Author(s)},
	issn = {1546-1718},
	url = {https://www.nature.com/articles/s41588-024-02053-6},
	doi = {10.1038/s41588-024-02053-6},
	abstract = {Sequence-based machine-learning models trained on genomics data improve genetic variant interpretation by providing functional predictions describing their impact on the cis-regulatory code. However, current tools do not predict RNA-seq expression profiles because of modeling challenges. Here, we introduce Borzoi, a model that learns to predict cell-type-specific and tissue-specific RNA-seq coverage from DNA sequence. Using statistics derived from Borzoi’s predicted coverage, we isolate and accurately score DNA variant effects across multiple layers of regulation, including transcription, splicing and polyadenylation. Evaluated on quantitative trait loci, Borzoi is competitive with and often outperforms state-of-the-art models trained on individual regulatory functions. By applying attribution methods to the derived statistics, we extract cis-regulatory motifs driving RNA expression and post-transcriptional regulation in normal tissues. The wide availability of RNA-seq data across species, conditions and assays profiling specific aspects of regulation emphasizes the potential of this approach to decipher the mapping from DNA sequence to regulatory function.},
	language = {en},
	number = {4},
	urldate = {2025-05-24},
	journal = {Nature Genetics},
	author = {Linder, Johannes and Srivastava, Divyanshi and Yuan, Han and Agarwal, Vikram and Kelley, David R.},
	month = jan,
	year = {2025},
	note = {66 citations (Crossref/DOI) [2025-10-22]
Publisher: Nature Publishing Group},
	keywords = {Printed, Important, Podcast},
	pages = {949--961},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/CZUJB3B3/2025-01-08 - Linder et al. - [Borzoi] Predicting RNA-seq coverage from DNA sequence as a unifying model of gene regulation.pdf:application/pdf},
}

@article{jaganathan_spliceai_2019,
	title = {[{SpliceAI}] {Predicting} {Splicing} from {Primary} {Sequence} with {Deep} {Learning}},
	volume = {176},
	issn = {0092-8674},
	url = {https://www.sciencedirect.com/science/article/pii/S0092867418316295},
	doi = {10.1016/j.cell.2018.12.015},
	abstract = {The splicing of pre-mRNAs into mature transcripts is remarkable for its precision, but the mechanisms by which the cellular machinery achieves such specificity are incompletely understood. Here, we describe a deep neural network that accurately predicts splice junctions from an arbitrary pre-mRNA transcript sequence, enabling precise prediction of noncoding genetic variants that cause cryptic splicing. Synonymous and intronic mutations with predicted splice-altering consequence validate at a high rate on RNA-seq and are strongly deleterious in the human population. De novo mutations with predicted splice-altering consequence are significantly enriched in patients with autism and intellectual disability compared to healthy controls and validate against RNA-seq in 21 out of 28 of these patients. We estimate that 9\%–11\% of pathogenic mutations in patients with rare genetic disorders are caused by this previously underappreciated class of disease variation.},
	number = {3},
	urldate = {2025-07-11},
	journal = {Cell},
	author = {Jaganathan, Kishore and Kyriazopoulou Panagiotopoulou, Sofia and McRae, Jeremy F. and Darbandi, Siavash Fazel and Knowles, David and Li, Yang I. and Kosmicki, Jack A. and Arbelaez, Juan and Cui, Wenwu and Schwartz, Grace B. and Chow, Eric D. and Kanterakis, Efstathios and Gao, Hong and Kia, Amirali and Batzoglou, Serafim and Sanders, Stephan J. and Farh, Kyle Kai-How},
	month = jan,
	year = {2019},
	note = {2156 citations (Crossref/DOI) [2025-10-22]},
	keywords = {Printed, Important, Podcast, Read},
	pages = {535--548.e24},
	file = {Full Text:/Users/meehl.joshua/Zotero/storage/RNFB2GEK/2019-01-24 - Jaganathan et al. - [SpliceAI] Predicting Splicing from Primary Sequence with Deep Learning.pdf:application/pdf;ScienceDirect Snapshot:/Users/meehl.joshua/Zotero/storage/7K7VMGER/S0092867418316295.html:text/html},
}

@article{yeo_maxentscan_2004,
	title = {Maximum {Entropy} {Modeling} of {Short} {Sequence} {Motifs} with {Applications} to {RNA} {Splicing} {Signals}},
	volume = {11},
	url = {https://www.liebertpub.com/doi/10.1089/1066527041410418},
	doi = {10.1089/1066527041410418},
	abstract = {We propose a framework for modeling sequence motifs based on the maximum entropy principle (MEP). We recommend approximating short sequence motif distributions with the maximum entropy distribution (MED) consistent with low-order marginal constraints estimated from available data, which may include dependencies between nonadjacent as well as adjacent positions. Many maximum entropy models (MEMs) are specified by simply changing the set of constraints. Such models can be utilized to discriminate between signals and decoys. Classification performance using different MEMs gives insight into the relative importance of dependencies between different positions. We apply our framework to large datasets of RNA splicing signals. Our best models out-perform previous probabilistic models in the discrimination of human 5′ (donor) and 3′ (acceptor) splice sites from decoys. Finally, we discuss mechanistically motivated ways of comparing models.},
	number = {2-3},
	urldate = {2025-12-15},
	journal = {Journal of Computational Biology},
	author = {Yeo, Gene and Burge, Christopher B.},
	month = mar,
	year = {2004},
	note = {Publisher: Mary Ann Liebert, Inc., publishers},
	pages = {377--394},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/I9R95NFQ/2004-03 - Yeo and Burge - Maximum Entropy Modeling of Short Sequence Motifs with Applications to RNA Splicing Signals.pdf:application/pdf},
}

@article{rentzsch_cadd_2019,
	title = {{CADD}: predicting the deleteriousness of variants throughout the human genome},
	volume = {47},
	issn = {0305-1048},
	shorttitle = {{CADD}},
	url = {https://doi.org/10.1093/nar/gky1016},
	doi = {10.1093/nar/gky1016},
	abstract = {Combined Annotation-Dependent Depletion (CADD) is a widely used measure of variant deleteriousness that can effectively prioritize causal variants in genetic analyses, particularly highly penetrant contributors to severe Mendelian disorders. CADD is an integrative annotation built from more than 60 genomic features, and can score human single nucleotide variants and short insertion and deletions anywhere in the reference assembly. CADD uses a machine learning model trained on a binary distinction between simulated de novo variants and variants that have arisen and become fixed in human populations since the split between humans and chimpanzees; the former are free of selective pressure and may thus include both neutral and deleterious alleles, while the latter are overwhelmingly neutral (or, at most, weakly deleterious) by virtue of having survived millions of years of purifying selection. Here we review the latest updates to CADD, including the most recent version, 1.4, which supports the human genome build GRCh38. We also present updates to our website that include simplified variant lookup, extended documentation, an Application Program Interface and improved mechanisms for integrating CADD scores into other tools or applications. CADD scores, software and documentation are available at https://cadd.gs.washington.edu.},
	number = {D1},
	urldate = {2025-12-02},
	journal = {Nucleic Acids Research},
	author = {Rentzsch, Philipp and Witten, Daniela and Cooper, Gregory M and Shendure, Jay and Kircher, Martin},
	month = jan,
	year = {2019},
	pages = {D886--D894},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/45CSF3AC/2019-01-08 - Rentzsch et al. - CADD predicting the deleteriousness of variants throughout the human genome.pdf:application/pdf;Snapshot:/Users/meehl.joshua/Zotero/storage/KMBY3G6E/gky1016.html:text/html},
}

@article{schubach_cadd_2024,
	title = {{CADD} v1.7: using protein language models, regulatory {CNNs} and other nucleotide-level scores to improve genome-wide variant predictions},
	volume = {52},
	issn = {0305-1048},
	shorttitle = {{CADD} v1.7},
	url = {https://doi.org/10.1093/nar/gkad989},
	doi = {10.1093/nar/gkad989},
	abstract = {Machine Learning-based scoring and classification of genetic variants aids the assessment of clinical findings and is employed to prioritize variants in diverse genetic studies and analyses. Combined Annotation-Dependent Depletion (CADD) is one of the first methods for the genome-wide prioritization of variants across different molecular functions and has been continuously developed and improved since its original publication. Here, we present our most recent release, CADD v1.7. We explored and integrated new annotation features, among them state-of-the-art protein language model scores (Meta ESM-1v), regulatory variant effect predictions (from sequence-based convolutional neural networks) and sequence conservation scores (Zoonomia). We evaluated the new version on data sets derived from ClinVar, ExAC/gnomAD and 1000 Genomes variants. For coding effects, we tested CADD on 31 Deep Mutational Scanning (DMS) data sets from ProteinGym and, for regulatory effect prediction, we used saturation mutagenesis reporter assay data of promoter and enhancer sequences. The inclusion of new features further improved the overall performance of CADD. As with previous releases, all data sets, genome-wide CADD v1.7 scores, scripts for on-site scoring and an easy-to-use webserver are readily provided via https://cadd.bihealth.org/ or https://cadd.gs.washington.edu/ to the community.},
	number = {D1},
	urldate = {2025-05-23},
	journal = {Nucleic Acids Research},
	author = {Schubach, Max and Maass, Thorben and Nazaretyan, Lusiné and Röner, Sebastian and Kircher, Martin},
	month = jan,
	year = {2024},
	note = {235 citations (Crossref/DOI) [2025-10-22]},
	keywords = {Printed, Podcast, Read},
	pages = {D1143--D1154},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/55MT7UQH/2024-01-05 - Schubach et al. - CADD v1.7 using protein language models, regulatory CNNs and other nucleotide-level scores to impro.pdf:application/pdf;Snapshot:/Users/meehl.joshua/Zotero/storage/X6G5SM2W/7511313.html:text/html},
}

@article{ng_sift_2003,
	title = {{SIFT}: {Predicting} amino acid changes that affect protein function},
	volume = {31},
	issn = {1362-4962},
	shorttitle = {{SIFT}},
	doi = {10.1093/nar/gkg509},
	abstract = {Single nucleotide polymorphism (SNP) studies and random mutagenesis projects identify amino acid substitutions in protein-coding regions. Each substitution has the potential to affect protein function. SIFT (Sorting Intolerant From Tolerant) is a program that predicts whether an amino acid substitution affects protein function so that users can prioritize substitutions for further study. We have shown that SIFT can distinguish between functionally neutral and deleterious amino acid changes in mutagenesis studies and on human polymorphisms. SIFT is available at http://blocks.fhcrc.org/sift/SIFT.html.},
	language = {eng},
	number = {13},
	journal = {Nucleic Acids Research},
	author = {Ng, Pauline C. and Henikoff, Steven},
	month = jul,
	year = {2003},
	pmid = {12824425},
	pmcid = {PMC168916},
	pages = {3812--3814},
	file = {Full Text:/Users/meehl.joshua/Zotero/storage/BUHJDQZ6/2003-07-01 - Ng and Henikoff - SIFT Predicting amino acid changes that affect protein function.pdf:application/pdf},
}

@article{adzhubei_polyphen_2010,
	title = {A method and server for predicting damaging missense mutations},
	volume = {7},
	copyright = {2010 Springer Nature America, Inc.},
	issn = {1548-7105},
	url = {https://www.nature.com/articles/nmeth0410-248},
	doi = {10.1038/nmeth0410-248},
	language = {en},
	number = {4},
	urldate = {2025-12-03},
	journal = {Nature Methods},
	author = {Adzhubei, Ivan A. and Schmidt, Steffen and Peshkin, Leonid and Ramensky, Vasily E. and Gerasimova, Anna and Bork, Peer and Kondrashov, Alexey S. and Sunyaev, Shamil R.},
	month = apr,
	year = {2010},
	note = {Publisher: Nature Publishing Group},
	pages = {248--249},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/3XQI8L66/2010-04 - Adzhubei et al. - A method and server for predicting damaging missense mutations.pdf:application/pdf},
}

@article{cheng_alphamissense_2023,
	title = {[{AlphaMissense}] {Accurate} proteome-wide missense variant effect prediction with {AlphaMissense}},
	volume = {381},
	url = {https://www.science.org/doi/full/10.1126/science.adg7492},
	doi = {10.1126/science.adg7492},
	abstract = {The vast majority of missense variants observed in the human genome are of unknown clinical significance. We present AlphaMissense, an adaptation of AlphaFold fine-tuned on human and primate variant population frequency databases to predict missense variant pathogenicity. By combining structural context and evolutionary conservation, our model achieves state-of-the-art results across a wide range of genetic and experimental benchmarks, all without explicitly training on such data. The average pathogenicity score of genes is also predictive for their cell essentiality, capable of identifying short essential genes that existing statistical approaches are underpowered to detect. As a resource to the community, we provide a database of predictions for all possible human single amino acid substitutions and classify 89\% of missense variants as either likely benign or likely pathogenic.},
	number = {6664},
	urldate = {2023-09-21},
	journal = {Science},
	author = {Cheng, Jun and Novati, Guido and Pan, Joshua and Bycroft, Clare and Žemgulytė, Akvilė and Applebaum, Taylor and Pritzel, Alexander and Wong, Lai Hong and Zielinski, Michal and Sargeant, Tobias and Schneider, Rosalia G. and Senior, Andrew W. and Jumper, John and Hassabis, Demis and Kohli, Pushmeet and Avsec, Žiga},
	month = sep,
	year = {2023},
	note = {1325 citations (Crossref/DOI) [2025-10-22]
Publisher: American Association for the Advancement of Science},
	keywords = {Printed, Read},
	pages = {eadg7492},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/MZM35E4X/2023-09-19 - Cheng et al. - [AlphaMissense] Accurate proteome-wide missense variant effect prediction with AlphaMissense.pdf:application/pdf;science.adg7492_sm:/Users/meehl.joshua/Zotero/storage/TXHUTZAK/science.adg7492_sm.pdf:application/pdf},
}

@article{benegas_gpn-msa_2024,
	title = {{GPN}-{MSA}: an alignment-based {DNA} language model for genome-wide variant effect prediction},
	issn = {2692-8205},
	shorttitle = {{GPN}-{MSA}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10592768/},
	doi = {10.1101/2023.10.10.561776},
	abstract = {Whereas protein language models have demonstrated remarkable efficacy in predicting the effects of missense variants, DNA counterparts have not yet achieved a similar competitive edge for genome-wide variant effect predictions, especially in complex genomes such as that of humans. To address this challenge, we here introduce GPN-MSA, a novel framework for DNA language models that leverages whole-genome sequence alignments across multiple species and takes only a few hours to train. Across several benchmarks on clinical databases (ClinVar, COSMIC, OMIM), experimental functional assays (DMS, DepMap), and population genomic data (gnomAD), our model for the human genome achieves outstanding performance on deleteriousness prediction for both coding and non-coding variants.},
	urldate = {2025-05-23},
	journal = {bioRxiv},
	author = {Benegas, Gonzalo and Albors, Carlos and Aw, Alan J. and Ye, Chengzhong and Song, Yun S.},
	month = apr,
	year = {2024},
	pmid = {37873118},
	pmcid = {PMC10592768},
	note = {19 citations (Crossref/DOI) [2025-10-22]
31 citations (Semantic Scholar/DOI) [2025-10-22]},
	keywords = {Printed, Podcast, Read},
	pages = {2023.10.10.561776},
	file = {Submitted Version:/Users/meehl.joshua/Zotero/storage/VU58S8BV/2024-04-06 - Benegas et al. - GPN-MSA an alignment-based DNA language model for genome-wide variant effect prediction.pdf:application/pdf},
}

@misc{brixi_evo_2025,
	title = {[{Evo} 2] {Genome} modeling and design across all domains of life with {Evo} 2},
	copyright = {© 2025, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2025.02.18.638918v1},
	doi = {10.1101/2025.02.18.638918},
	abstract = {All of life encodes information with DNA. While tools for sequencing, synthesis, and editing of genomic code have transformed biological research, intelligently composing new biological systems would also require a deep understanding of the immense complexity encoded by genomes. We introduce Evo 2, a biological foundation model trained on 9.3 trillion DNA base pairs from a highly curated genomic atlas spanning all domains of life. We train Evo 2 with 7B and 40B parameters to have an unprecedented 1 million token context window with single-nucleotide resolution. Evo 2 learns from DNA sequence alone to accurately predict the functional impacts of genetic variation—from noncoding pathogenic mutations to clinically significant BRCA1 variants—without task-specific finetuning. Applying mechanistic interpretability analyses, we reveal that Evo 2 autonomously learns a breadth of biological features, including exon–intron boundaries, transcription factor binding sites, protein structural elements, and prophage genomic regions. Beyond its predictive capabilities, Evo 2 generates mitochondrial, prokaryotic, and eukaryotic sequences at genome scale with greater naturalness and coherence than previous methods. Guiding Evo 2 via inference-time search enables controllable generation of epigenomic structure, for which we demonstrate the first inference-time scaling results in biology. We make Evo 2 fully open, including model parameters, training code, inference code, and the OpenGenome2 dataset, to accelerate the exploration and design of biological complexity.},
	language = {en},
	urldate = {2025-02-26},
	publisher = {bioRxiv},
	author = {Brixi, Garyk and Durrant, Matthew G. and Ku, Jerome and Poli, Michael and Brockman, Greg and Chang, Daniel and Gonzalez, Gabriel A. and King, Samuel H. and Li, David B. and Merchant, Aditi T. and Naghipourfar, Mohsen and Nguyen, Eric and Ricci-Tam, Chiara and Romero, David W. and Sun, Gwanggyu and Taghibakshi, Ali and Vorontsov, Anton and Yang, Brandon and Deng, Myra and Gorton, Liv and Nguyen, Nam and Wang, Nicholas K. and Adams, Etowah and Baccus, Stephen A. and Dillmann, Steven and Ermon, Stefano and Guo, Daniel and Ilango, Rajesh and Janik, Ken and Lu, Amy X. and Mehta, Reshma and Mofrad, Mohammad R. K. and Ng, Madelena Y. and Pannu, Jaspreet and Ré, Christopher and Schmok, Jonathan C. and John, John St and Sullivan, Jeremy and Zhu, Kevin and Zynda, Greg and Balsam, Daniel and Collison, Patrick and Costa, Anthony B. and Hernandez-Boussard, Tina and Ho, Eric and Liu, Ming-Yu and McGrath, Thomas and Powell, Kimberly and Burke, Dave P. and Goodarzi, Hani and Hsu, Patrick D. and Hie, Brian L.},
	month = feb,
	year = {2025},
	note = {71 citations (Crossref/DOI) [2025-10-22]
Pages: 2025.02.18.638918
Section: New Results},
	keywords = {Printed, Important, Podcast, Read},
	file = {2025-02-21 - Brixi et al. - [Evo 2] Genome modeling and design across all domains of life with Evo 2:/Users/meehl.joshua/Zotero/storage/BSMA7JT7/2025-02-21 - Brixi et al. - [Evo 2] Genome modeling and design across all domains of life with Evo 2.pdf:application/pdf},
}

@misc{avsec_alphagenome_2025,
	title = {{AlphaGenome}: {AI} for better understanding the genome},
	shorttitle = {{AlphaGenome}},
	url = {https://deepmind.google/discover/blog/alphagenome-ai-for-better-understanding-the-genome/},
	abstract = {Introducing a new, unifying DNA sequence model that advances regulatory variant-effect prediction and promises to shed new light on genome function — now available via API.},
	language = {en},
	urldate = {2025-06-27},
	journal = {Google DeepMind},
	author = {Avsec, Ziga and Latysheva, Natasha and Cheng, Jun},
	month = jun,
	year = {2025},
	keywords = {Printed, Important, Podcast},
	file = {2025-06-25 - Avsec et al. - AlphaGenome AI for better understanding the genome:/Users/meehl.joshua/Zotero/storage/397U6HN6/2025-06-25 - Avsec et al. - AlphaGenome AI for better understanding the genome.pdf:application/pdf},
}

@misc{georgantas_delphi_2024,
	title = {Delphi: {A} {Deep}-learning {Method} for {Polygenic} {Risk} {Prediction}},
	copyright = {© 2024, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at http://creativecommons.org/licenses/by-nc/4.0/},
	shorttitle = {Delphi},
	url = {https://www.medrxiv.org/content/10.1101/2024.04.19.24306079v2},
	doi = {10.1101/2024.04.19.24306079},
	abstract = {Polygenic risk scores (PRS) are relative measures of an individual’s genetic propensity to a particular trait or disease. Most PRS methods assume that mutation effects scale linearly with the number of alleles and are constant across individuals. While these assumptions simplify computation, they increase error, particularly for less-represented racial groups. We developed and provide Delphi (deep learning for phenotype inference), a deep-learning method that relaxes these assumptions to produce more predictive PRS. In contrast to other methods, Delphi can integrate up to hundreds of thousands of SNPs as input. We compare our results to a standard, linear PRS model, lasso regression, and a gradient-boosted trees-based method. We show that deep learning can be an effective approach to genetic risk prediction. We report a relative increase in the percentage variance explained compared to the state-of-the-art by 11.4\% for body mass index, 18.9\% for systolic blood pressure, 7.5\% for LDL, 35\% for C-reactive protein, 16.2\% for height, 29.6 \% for pulse rate; in addition, Delphi provides 2\% absolute explained variance for blood glucose while other tested methods were non-predictive. Furthermore, we show that Delphi tends to increase the weight of high-effect mutations. This work demonstrates an effective deep learning method for modeling genetic risk that also showed to generalize well when evaluated on individuals from non-European ancestries.},
	language = {en},
	urldate = {2025-07-12},
	publisher = {medRxiv},
	author = {Georgantas, Costa and Kutalik, Zoltán and Richiardi, Jonas},
	month = jul,
	year = {2024},
	note = {3 citations (Crossref/DOI) [2025-10-22]
Pages: 2024.04.19.24306079},
	keywords = {Printed, Podcast},
	file = {PDF:/Users/meehl.joshua/Zotero/storage/YHXTGSCR/2024-07-02 - Georgantas et al. - Delphi A Deep-learning Method for Polygenic Risk Prediction.pdf:application/pdf},
}

@misc{rakowski_mifm_2025,
	title = {[{MIFM}] {Multiple} instance fine-mapping: predicting causal regulatory variants with a deep sequence model},
	copyright = {© 2025, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	shorttitle = {Multiple instance fine-mapping},
	url = {https://www.medrxiv.org/content/10.1101/2025.06.13.25329551v1},
	doi = {10.1101/2025.06.13.25329551},
	abstract = {Identifying causal genetic variants in a computational manner remains an open problem. Training end-to-end prediction models is not possible without large ground-truth datasets, while results of genome-wide association studies (GWAS) are entangled by linkage disequilibrium (LD), and gene expression datasets do not contain genetic variation at individual-level. Here, we propose Multiple Instance Fine-mapping (MIFM) – a multiple instance learning (MIL) objective to overcome the lack of strong labels by grouping putatively causal variants together based on their LD scores. Using MIFM, we trained a deep classifier on a dataset aggregating over 13, 000 GWAS to predict causal variants based on their underlying DNA sequences. We validated variants prioritized by MIFM by constructing polygenic risk scores which transferred better to different target ancestries. Furthermore, we demonstrated how MIFM can be used to disentangle effect sizes of highly-correlated variants to better fine-map GWAS results.
Author summary Genome-wide association studies have identified tens of thousands genetic variants associated with traits or diseases. However, the majority of identified variants is only spuriously correlated with the phenotype of interest, having no causal effect on it. Instead, these variants are often inherited together with nearby biologically causal variants, thus creating the spurious associations. Fine-mapping, i.e., predicting which variants are causal, is crucial for downstream tasks, such as uncovering the biological mechanisms affecting the phenotype or robustly identifying individuals with high genetic risk of a disease. While most fine-mapping methods are based on the available association statistics or functional annotations of genetic regions, it should be possible to identify causal variants based on their neighboring DNA sequences. However, training a standard machine learning classifier for that task is obstructed by the scarcity of strong, ground-truth labels. Here, we proposed a method to train sequence models predicting variant causality using weakly-labeled data. We trained a model on a large set of associated variants, and demonstrated its utility by improving cross-ancestry predictions of genetic risk, or disentangling the effect sizes of highly correlated variants.},
	language = {en},
	urldate = {2025-07-11},
	publisher = {medRxiv},
	author = {Rakowski, Alexander and Lippert, Christoph},
	month = jun,
	year = {2025},
	note = {0 citations (Crossref/DOI) [2025-10-22]
Pages: 2025.06.13.25329551},
	keywords = {Printed, Podcast, Recall},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/AI64IU6X/2025-06-14 - Rakowski and Lippert - [MIFM] Multiple instance fine-mapping predicting causal regulatory variants with a deep sequence mo.pdf:application/pdf},
}

@article{clarke_deeprvat_2024,
	title = {[{DeepRVAT}] {Integration} of variant annotations using deep set networks boosts rare variant association testing},
	volume = {56},
	copyright = {2024 The Author(s)},
	issn = {1546-1718},
	url = {https://www.nature.com/articles/s41588-024-01919-z},
	doi = {10.1038/s41588-024-01919-z},
	abstract = {Rare genetic variants can have strong effects on phenotypes, yet accounting for rare variants in genetic analyses is statistically challenging due to the limited number of allele carriers and the burden of multiple testing. While rich variant annotations promise to enable well-powered rare variant association tests, methods integrating variant annotations in a data-driven manner are lacking. Here we propose deep rare variant association testing (DeepRVAT), a model based on set neural networks that learns a trait-agnostic gene impairment score from rare variant annotations and phenotypes, enabling both gene discovery and trait prediction. On 34 quantitative and 63 binary traits, using whole-exome-sequencing data from UK Biobank, we find that DeepRVAT yields substantial gains in gene discoveries and improved detection of individuals at high genetic risk. Finally, we demonstrate how DeepRVAT enables calibrated and computationally efficient rare variant tests at biobank scale, aiding the discovery of genetic risk factors for human disease traits.},
	language = {en},
	number = {10},
	urldate = {2025-07-12},
	journal = {Nature Genetics},
	author = {Clarke, Brian and Holtkamp, Eva and Öztürk, Hakime and Mück, Marcel and Wahlberg, Magnus and Meyer, Kayla and Munzlinger, Felix and Brechtmann, Felix and Hölzlwimmer, Florian R. and Lindner, Jonas and Chen, Zhifen and Gagneur, Julien and Stegle, Oliver},
	month = sep,
	year = {2024},
	note = {12 citations (Crossref/DOI) [2025-10-22]
Publisher: Nature Publishing Group},
	keywords = {Printed, Podcast},
	pages = {2271--2280},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/G5IIH2WR/2024-09-25 - Clarke et al. - [DeepRVAT] Integration of variant annotations using deep set networks boosts rare variant associatio.pdf:application/pdf},
}

@misc{lee_g2pt_2025,
	title = {[{G2PT}] {A} genotype-phenotype transformer to assess and explain polygenic risk},
	copyright = {© 2025, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/2024.10.23.619940v2},
	doi = {10.1101/2024.10.23.619940},
	abstract = {Genome-wide association studies have linked millions of genetic variants to biomedical phenotypes, but their utility has been limited by lack of mechanistic understanding and widespread epistatic interactions. Recently, Transformer models have emerged as a powerful machine learning architecture with potential to address these and other challenges. Accordingly, here we introduce the Genotype-to-Phenotype Transformer (G2PT), a framework for modeling hierarchical information flow among variants, genes, multigenic systems, and phenotypes. As proof-of-concept, we use G2PT to model the genetics of TG/HDL (triglycerides to high-density lipoprotein cholesterol), an indicator of metabolic health. G2PT predicts this trait via attention to 1,395 variants underlying at least 20 systems, including immune response and cholesterol transport, with accuracy exceeding state-of-the-art. It implicates 40 epistatic interactions, including epistasis between APOA4 and CETP in phospholipid transfer, a target pathway for cholesterol modification. This work positions hierarchical graph transformers as a next-generation approach to polygenic risk.},
	language = {en},
	urldate = {2025-05-28},
	publisher = {bioRxiv},
	author = {Lee, Ingoo and Wallace, Zachary S. and Wang, Yuqi and Park, Sungjoon and Nam, Hojung and Majithia, Amit R. and Ideker, Trey},
	month = apr,
	year = {2025},
	note = {1 citations (Crossref/DOI) [2025-10-22]
Pages: 2024.10.23.619940
Section: New Results},
	keywords = {Printed, Podcast, Recall},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/2ZPTDM6K/2025-04-11 - Lee et al. - [G2PT] A genotype-phenotype transformer to assess and explain polygenic risk.pdf:application/pdf},
}

@article{cao_glue_2022,
	title = {[{GLUE}] {Multi}-omics single-cell data integration and regulatory inference with graph-linked embedding},
	volume = {40},
	copyright = {2022 The Author(s)},
	issn = {1546-1696},
	url = {https://www.nature.com/articles/s41587-022-01284-4},
	doi = {10.1038/s41587-022-01284-4},
	abstract = {Despite the emergence of experimental methods for simultaneous measurement of multiple omics modalities in single cells, most single-cell datasets include only one modality. A major obstacle in integrating omics data from multiple modalities is that different omics layers typically have distinct feature spaces. Here, we propose a computational framework called GLUE (graph-linked unified embedding), which bridges the gap by modeling regulatory interactions across omics layers explicitly. Systematic benchmarking demonstrated that GLUE is more accurate, robust and scalable than state-of-the-art tools for heterogeneous single-cell multi-omics data. We applied GLUE to various challenging tasks, including triple-omics integration, integrative regulatory inference and multi-omics human cell atlas construction over millions of cells, where GLUE was able to correct previous annotations. GLUE features a modular design that can be flexibly extended and enhanced for new analysis tasks. The full package is available online at https://github.com/gao-lab/GLUE.},
	language = {en},
	number = {10},
	urldate = {2025-07-12},
	journal = {Nature Biotechnology},
	author = {Cao, Zhi-Jie and Gao, Ge},
	month = may,
	year = {2022},
	note = {397 citations (Crossref/DOI) [2025-10-22]
Publisher: Nature Publishing Group},
	keywords = {Printed, Read},
	pages = {1458--1466},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/M96CQGML/2022-05-02 - Cao and Gao - [GLUE] Multi-omics single-cell data integration and regulatory inference with graph-linked embedding.pdf:application/pdf},
}

@article{li_mogcn_2022,
	title = {{MoGCN}: {A} {Multi}-{Omics} {Integration} {Method} {Based} on {Graph} {Convolutional} {Network} for {Cancer} {Subtype} {Analysis}},
	volume = {13},
	issn = {1664-8021},
	shorttitle = {{MoGCN}},
	url = {https://www.frontiersin.org/journals/genetics/articles/10.3389/fgene.2022.806842/full},
	doi = {10.3389/fgene.2022.806842},
	abstract = {In light of the rapid accumulation of large-scale omics datasets, numerous studies have attempted to characterize the molecular and clinical features of cancers from a multi-omics perspective. However, there are great challenges in integrating multi-omics using machine learning methods for cancer subtype classification. In this study, MoGCN, a multi-omics integration model based on graph convolutional network (GCN) was developed for cancer subtype classification and analysis. Genomics, transcriptomics and proteomics datasets for 511 breast invasive carcinoma (BRCA) samples were downloaded from the Cancer Genome Atlas (TCGA). The autoencoder (AE) and the similarity network fusion (SNF) methods were used to reduce dimensionality and construct the patient similarity network (PSN), respectively. Then the vector features and the PSN were input into the GCN for training and testing. Feature extraction and network visualization were used for further biological knowledge discovery and subtype classification. In the analysis of multi-dimensional omics data of the BRCA samples in TCGA, MoGCN achieved the highest accuracy in cancer subtype classification compared with several popular algorithms. Moreover, MoGCN can extract the most significant features of each omics layer and provide candidate functional molecules for further analysis of their biological effects. And network visualization showed that MoGCN could make clinically intuitive diagnosis. The generality of MoGCN was proven on the TCGA pan-kidney cancer datasets. MoGCN and datasets are public available at https://github.com/Lifoof/MoGCN. Our study shows that MoGCN performs well for heterogeneous data integration and the interpretability of classification results, which confers great potential for applications in biomarker identification and clinical diagnosis.},
	language = {English},
	urldate = {2025-07-12},
	journal = {Frontiers in Genetics},
	author = {Li, Xiao and Ma, Jie and Leng, Ling and Han, Mingfei and Li, Mansheng and He, Fuchu and Zhu, Yunping},
	month = feb,
	year = {2022},
	note = {90 citations (Crossref/DOI) [2025-10-22]
Publisher: Frontiers},
	keywords = {Printed, Read},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/NTWP6PXW/2022-02-02 - Li et al. - MoGCN A Multi-Omics Integration Method Based on Graph Convolutional Network for Cancer Subtype Anal.pdf:application/pdf},
}

@article{li_cgmega_2024,
	title = {{CGMega}: explainable graph neural network framework with attention mechanisms for cancer gene module dissection},
	volume = {15},
	copyright = {2024 The Author(s)},
	issn = {2041-1723},
	shorttitle = {{CGMega}},
	url = {https://www.nature.com/articles/s41467-024-50426-6},
	doi = {10.1038/s41467-024-50426-6},
	abstract = {Cancer is rarely the straightforward consequence of an abnormality in a single gene, but rather reflects a complex interplay of many genes, represented as gene modules. Here, we leverage the recent advances of model-agnostic interpretation approach and develop CGMega, an explainable and graph attention-based deep learning framework to perform cancer gene module dissection. CGMega outperforms current approaches in cancer gene prediction, and it provides a promising approach to integrate multi-omics information. We apply CGMega to breast cancer cell line and acute myeloid leukemia (AML) patients, and we uncover the high-order gene module formed by ErbB family and tumor factors NRG1, PPM1A and DLG2. We identify 396 candidate AML genes, and observe the enrichment of either known AML genes or candidate AML genes in a single gene module. We also identify patient-specific AML genes and associated gene modules. Together, these results indicate that CGMega can be used to dissect cancer gene modules, and provide high-order mechanistic insights into cancer development and heterogeneity.},
	language = {en},
	number = {1},
	urldate = {2025-06-05},
	journal = {Nature Communications},
	author = {Li, Hao and Han, Zebei and Sun, Yu and Wang, Fu and Hu, Pengzhen and Gao, Yuang and Bai, Xuemei and Peng, Shiyu and Ren, Chao and Xu, Xiang and Liu, Zeyu and Chen, Hebing and Yang, Yang and Bo, Xiaochen},
	month = jul,
	year = {2024},
	note = {33 citations (Crossref/DOI) [2025-10-22]
Publisher: Nature Publishing Group},
	keywords = {Printed, Podcast},
	pages = {5997},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/NP5DWLR5/2024-07-17 - Li et al. - CGMega explainable graph neural network framework with attention mechanisms for cancer gene module.pdf:application/pdf},
}

@article{jumper_alphafold2_2021,
	title = {[{AlphaFold2}] {Highly} accurate protein structure prediction with {AlphaFold}},
	volume = {596},
	issn = {1476-4687},
	doi = {10.1038/s41586-021-03819-2},
	abstract = {Proteins are essential to life, and understanding their structure can facilitate a mechanistic understanding of their function. Through an enormous experimental effort1-4, the structures of around 100,000 unique proteins have been determined5, but this represents a small fraction of the billions of known protein sequences6,7. Structural coverage is bottlenecked by the months to years of painstaking effort required to determine a single protein structure. Accurate computational approaches are needed to address this gap and to enable large-scale structural bioinformatics. Predicting the three-dimensional structure that a protein will adopt based solely on its amino acid sequence-the structure prediction component of the 'protein folding problem'8-has been an important open research problem for more than 50 years9. Despite recent progress10-14, existing methods fall far short of atomic accuracy, especially when no homologous structure is available. Here we provide the first computational method that can regularly predict protein structures with atomic accuracy even in cases in which no similar structure is known. We validated an entirely redesigned version of our neural network-based model, AlphaFold, in the challenging 14th Critical Assessment of protein Structure Prediction (CASP14)15, demonstrating accuracy competitive with experimental structures in a majority of cases and greatly outperforming other methods. Underpinning the latest version of AlphaFold is a novel machine learning approach that incorporates physical and biological knowledge about protein structure, leveraging multi-sequence alignments, into the design of the deep learning algorithm.},
	language = {eng},
	number = {7873},
	journal = {Nature},
	author = {Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and Žídek, Augustin and Potapenko, Anna and Bridgland, Alex and Meyer, Clemens and Kohl, Simon A. A. and Ballard, Andrew J. and Cowie, Andrew and Romera-Paredes, Bernardino and Nikolov, Stanislav and Jain, Rishub and Adler, Jonas and Back, Trevor and Petersen, Stig and Reiman, David and Clancy, Ellen and Zielinski, Michal and Steinegger, Martin and Pacholska, Michalina and Berghammer, Tamas and Bodenstein, Sebastian and Silver, David and Vinyals, Oriol and Senior, Andrew W. and Kavukcuoglu, Koray and Kohli, Pushmeet and Hassabis, Demis},
	month = jul,
	year = {2021},
	pmid = {34265844},
	pmcid = {PMC8371605},
	note = {34742 citations (Crossref/DOI) [2025-10-22]},
	pages = {583--589},
	file = {Jumper et al. - 2021 - Highly accurate protein structure prediction with .pdf:/Users/meehl.joshua/Zotero/storage/SWMRH2BJ/2021-07-15 - Jumper et al. - [AlphaFold2] Highly accurate protein structure prediction with AlphaFold.pdf:application/pdf},
}

@article{abramson_alphafold3_2024,
	title = {[{AlphaFold3}] {Accurate} structure prediction of biomolecular interactions with {AlphaFold} 3},
	volume = {630},
	copyright = {2024 The Author(s)},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-024-07487-w},
	doi = {10.1038/s41586-024-07487-w},
	abstract = {The introduction of AlphaFold 21 has spurred a revolution in modelling the structure of proteins and their interactions, enabling a huge range of applications in protein modelling and design2–6. Here we describe our AlphaFold 3 model with a substantially updated diffusion-based architecture that is capable of predicting the joint structure of complexes including proteins, nucleic acids, small molecules, ions and modified residues. The new AlphaFold model demonstrates substantially improved accuracy over many previous specialized tools: far greater accuracy for protein–ligand interactions compared with state-of-the-art docking tools, much higher accuracy for protein–nucleic acid interactions compared with nucleic-acid-specific predictors and substantially higher antibody–antigen prediction accuracy compared with AlphaFold-Multimer v.2.37,8. Together, these results show that high-accuracy modelling across biomolecular space is possible within a single unified deep-learning framework.},
	language = {en},
	number = {8016},
	urldate = {2025-07-11},
	journal = {Nature},
	author = {Abramson, Josh and Adler, Jonas and Dunger, Jack and Evans, Richard and Green, Tim and Pritzel, Alexander and Ronneberger, Olaf and Willmore, Lindsay and Ballard, Andrew J. and Bambrick, Joshua and Bodenstein, Sebastian W. and Evans, David A. and Hung, Chia-Chun and O’Neill, Michael and Reiman, David and Tunyasuvunakool, Kathryn and Wu, Zachary and Žemgulytė, Akvilė and Arvaniti, Eirini and Beattie, Charles and Bertolli, Ottavia and Bridgland, Alex and Cherepanov, Alexey and Congreve, Miles and Cowen-Rivers, Alexander I. and Cowie, Andrew and Figurnov, Michael and Fuchs, Fabian B. and Gladman, Hannah and Jain, Rishub and Khan, Yousuf A. and Low, Caroline M. R. and Perlin, Kuba and Potapenko, Anna and Savy, Pascal and Singh, Sukhdeep and Stecula, Adrian and Thillaisundaram, Ashok and Tong, Catherine and Yakneen, Sergei and Zhong, Ellen D. and Zielinski, Michal and Žídek, Augustin and Bapst, Victor and Kohli, Pushmeet and Jaderberg, Max and Hassabis, Demis and Jumper, John M.},
	month = may,
	year = {2024},
	note = {7239 citations (Crossref/DOI) [2025-10-22]
5776 citations (Semantic Scholar/DOI) [2025-10-22]
7239 citations (Crossref/DOI) [2025-10-22]
Publisher: Nature Publishing Group},
	keywords = {Important},
	pages = {493--500},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/IMVZAJZR/2024-05-08 - Abramson et al. - [AlphaFold3] Accurate structure prediction of biomolecular interactions with AlphaFold 3.pdf:application/pdf},
}

@article{siepel_phastcons_2005,
	title = {[{PhastCons}] {Evolutionarily} conserved elements in vertebrate, insect, worm, and yeast genomes},
	volume = {15},
	issn = {1088-9051},
	doi = {10.1101/gr.3715005},
	abstract = {We have conducted a comprehensive search for conserved elements in vertebrate genomes, using genome-wide multiple alignments of five vertebrate species (human, mouse, rat, chicken, and Fugu rubripes). Parallel searches have been performed with multiple alignments of four insect species (three species of Drosophila and Anopheles gambiae), two species of Caenorhabditis, and seven species of Saccharomyces. Conserved elements were identified with a computer program called phastCons, which is based on a two-state phylogenetic hidden Markov model (phylo-HMM). PhastCons works by fitting a phylo-HMM to the data by maximum likelihood, subject to constraints designed to calibrate the model across species groups, and then predicting conserved elements based on this model. The predicted elements cover roughly 3\%-8\% of the human genome (depending on the details of the calibration procedure) and substantially higher fractions of the more compact Drosophila melanogaster (37\%-53\%), Caenorhabditis elegans (18\%-37\%), and Saccharaomyces cerevisiae (47\%-68\%) genomes. From yeasts to vertebrates, in order of increasing genome size and general biological complexity, increasing fractions of conserved bases are found to lie outside of the exons of known protein-coding genes. In all groups, the most highly conserved elements (HCEs), by log-odds score, are hundreds or thousands of bases long. These elements share certain properties with ultraconserved elements, but they tend to be longer and less perfectly conserved, and they overlap genes of somewhat different functional categories. In vertebrates, HCEs are associated with the 3' UTRs of regulatory genes, stable gene deserts, and megabase-sized regions rich in moderately conserved noncoding sequences. Noncoding HCEs also show strong statistical evidence of an enrichment for RNA secondary structure.},
	language = {eng},
	number = {8},
	journal = {Genome Research},
	author = {Siepel, Adam and Bejerano, Gill and Pedersen, Jakob S. and Hinrichs, Angie S. and Hou, Minmei and Rosenbloom, Kate and Clawson, Hiram and Spieth, John and Hillier, Ladeana W. and Richards, Stephen and Weinstock, George M. and Wilson, Richard K. and Gibbs, Richard A. and Kent, W. James and Miller, Webb and Haussler, David},
	month = aug,
	year = {2005},
	pmid = {16024819},
	pmcid = {PMC1182216},
	pages = {1034--1050},
	file = {Full Text:/Users/meehl.joshua/Zotero/storage/B4H9S59F/2005-08 - Siepel et al. - Evolutionarily conserved elements in vertebrate, insect, worm, and yeast genomes.pdf:application/pdf},
}

@article{davydov_gerp_2010,
	title = {Identifying a {High} {Fraction} of the {Human} {Genome} to be under {Selective} {Constraint} {Using} {GERP}++},
	volume = {6},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1001025},
	doi = {10.1371/journal.pcbi.1001025},
	abstract = {Computational efforts to identify functional elements within genomes leverage comparative sequence information by looking for regions that exhibit evidence of selective constraint. One way of detecting constrained elements is to follow a bottom-up approach by computing constraint scores for individual positions of a multiple alignment and then defining constrained elements as segments of contiguous, highly scoring nucleotide positions. Here we present GERP++, a new tool that uses maximum likelihood evolutionary rate estimation for position-specific scoring and, in contrast to previous bottom-up methods, a novel dynamic programming approach to subsequently define constrained elements. GERP++ evaluates a richer set of candidate element breakpoints and ranks them based on statistical significance, eliminating the need for biased heuristic extension techniques. Using GERP++ we identify over 1.3 million constrained elements spanning over 7\% of the human genome. We predict a higher fraction than earlier estimates largely due to the annotation of longer constrained elements, which improves one to one correspondence between predicted elements with known functional sequences. GERP++ is an efficient and effective tool to provide both nucleotide- and element-level constraint scores within deep multiple sequence alignments.},
	language = {en},
	number = {12},
	urldate = {2025-12-03},
	journal = {PLOS Computational Biology},
	author = {Davydov, Eugene V. and Goode, David L. and Sirota, Marina and Cooper, Gregory M. and Sidow, Arend and Batzoglou, Serafim},
	month = dec,
	year = {2010},
	note = {Publisher: Public Library of Science},
	pages = {e1001025},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/SQKEUHCK/Dec 2, 2010 - Davydov et al. - Identifying a High Fraction of the Human Genome to be under Selective Constraint Using GERP++.pdf:application/pdf},
}
