@misc{camillo_cpgpt_2024,
	title = {{CpGPT}: a {Foundation} {Model} for {DNA} {Methylation}},
	copyright = {© 2024, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	shorttitle = {{CpGPT}},
	url = {https://www.biorxiv.org/content/10.1101/2024.10.24.619766v1},
	doi = {10.1101/2024.10.24.619766},
	abstract = {DNA methylation is a critical epigenetic modification that regulates gene expression and plays a significant role in development and disease processes. Here, we present the Cytosine-phosphate-Guanine Pretrained Transformer (CpGPT), a novel foundation model pretrained on over 1,500 DNA methylation datasets encompassing over 100,000 samples from diverse tissues and conditions. CpGPT leverages an improved transformer architecture to learn comprehensive representations of methylation patterns, allowing it to impute and reconstruct genome-wide methylation profiles from limited input data. By capturing sequence, positional, and epigenetic contexts, CpGPT outperforms specialized models when finetuned for aging-related tasks, including chronological age prediction, mortality risk, and morbidity assessments. The model is highly adaptable across different methylation platforms and tissue types. Furthermore, analysis of sample-specific attention weights enables the identification of the most influential CpG sites for individual predictions. As a foundation model, CpGPT sets a new benchmark for DNA methylation analysis, achieving strong performance in the Biomarkers of Aging Challenge, where it placed second overall in chronological age estimation and first on the public leaderboard in methylation-based mortality prediction.
HighlightsCpGPT is a novel foundation model for DNA methylation analysis, pretrained on over 1,500 datasets encompassing 100,000+ samples.The model demonstrates strong performance in zero-shot tasks including imputation, array conversion, and reference mapping.CpGPT achieves state-of-the-art results in mortality prediction and chronological age estimation.Sample-specific interpretability is enabled through analysis of attention weights.},
	language = {en},
	urldate = {2025-07-05},
	publisher = {bioRxiv},
	author = {Camillo, Lucas Paulo de Lima and Sehgal, Raghav and Armstrong, Jenel and Higgins-Chen, Albert T. and Horvath, Steve and Wang, Bo},
	month = oct,
	year = {2024},
	note = {17 citations (Crossref/DOI) [2025-10-22]
Pages: 2024.10.24.619766
Section: New Results},
	keywords = {Printed, Podcast},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/BD6NXKAF/2024-10-29 - Camillo et al. - CpGPT a Foundation Model for DNA Methylation.pdf:application/pdf},
}

@article{cao_glue_2022,
	title = {[{GLUE}] {Multi}-omics single-cell data integration and regulatory inference with graph-linked embedding},
	volume = {40},
	copyright = {2022 The Author(s)},
	issn = {1546-1696},
	url = {https://www.nature.com/articles/s41587-022-01284-4},
	doi = {10.1038/s41587-022-01284-4},
	abstract = {Despite the emergence of experimental methods for simultaneous measurement of multiple omics modalities in single cells, most single-cell datasets include only one modality. A major obstacle in integrating omics data from multiple modalities is that different omics layers typically have distinct feature spaces. Here, we propose a computational framework called GLUE (graph-linked unified embedding), which bridges the gap by modeling regulatory interactions across omics layers explicitly. Systematic benchmarking demonstrated that GLUE is more accurate, robust and scalable than state-of-the-art tools for heterogeneous single-cell multi-omics data. We applied GLUE to various challenging tasks, including triple-omics integration, integrative regulatory inference and multi-omics human cell atlas construction over millions of cells, where GLUE was able to correct previous annotations. GLUE features a modular design that can be flexibly extended and enhanced for new analysis tasks. The full package is available online at https://github.com/gao-lab/GLUE.},
	language = {en},
	number = {10},
	urldate = {2025-07-12},
	journal = {Nature Biotechnology},
	author = {Cao, Zhi-Jie and Gao, Ge},
	month = may,
	year = {2022},
	note = {397 citations (Crossref/DOI) [2025-10-22]
Publisher: Nature Publishing Group},
	keywords = {Printed, Read},
	pages = {1458--1466},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/M96CQGML/2022-05-02 - Cao and Gao - [GLUE] Multi-omics single-cell data integration and regulatory inference with graph-linked embedding.pdf:application/pdf},
}
@article{cui_scgpt_2024,
	title = {{scGPT}: toward building a foundation model for single-cell multi-omics using generative {AI}},
	volume = {21},
	copyright = {2024 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1548-7105},
	shorttitle = {{scGPT}},
	url = {https://www.nature.com/articles/s41592-024-02201-0},
	doi = {10.1038/s41592-024-02201-0},
	abstract = {Generative pretrained models have achieved remarkable success in various domains such as language and computer vision. Specifically, the combination of large-scale diverse datasets and pretrained transformers has emerged as a promising approach for developing foundation models. Drawing parallels between language and cellular biology (in which texts comprise words; similarly, cells are defined by genes), our study probes the applicability of foundation models to advance cellular biology and genetic research. Using burgeoning single-cell sequencing data, we have constructed a foundation model for single-cell biology, scGPT, based on a generative pretrained transformer across a repository of over 33 million cells. Our findings illustrate that scGPT effectively distills critical biological insights concerning genes and cells. Through further adaptation of transfer learning, scGPT can be optimized to achieve superior performance across diverse downstream applications. This includes tasks such as cell type annotation, multi-batch integration, multi-omic integration, perturbation response prediction and gene network inference.},
	language = {en},
	number = {8},
	urldate = {2025-07-05},
	journal = {Nature Methods},
	author = {Cui, Haotian and Wang, Chloe and Maan, Hassaan and Pang, Kuan and Luo, Fengning and Duan, Nan and Wang, Bo},
	month = feb,
	year = {2024},
	note = {496 citations (Crossref/DOI) [2025-10-22]
Publisher: Nature Publishing Group},
	pages = {1470--1480},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/GB9APSA3/2024-08 - Cui et al. - scGPT toward building a foundation model for single-cell multi-omics using generative AI.pdf:application/pdf},
}

@misc{dixit_perturb-seq_2016,
  title = {Missing reference for dixit_perturb-seq_2016},
  note = {TODO: add full BibTeX entry},
}

@misc{hao_scfoundation_2024,
  title = {Missing reference for hao_scfoundation_2024},
  note = {TODO: add full BibTeX entry},
}

@misc{pearce_transcriptformer_2025,
	title = {[{TranscriptFormer}] {Cross}-{Species} {Generative} {Cell} {Atlas} {Across} 1.5 {Billion} {Years} of {Evolution}: {The} {TranscriptFormer} {Single}-cell {Model}},
	copyright = {© 2025, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	shorttitle = {A {Cross}-{Species} {Generative} {Cell} {Atlas} {Across} 1.5 {Billion} {Years} of {Evolution}},
	url = {https://www.biorxiv.org/content/10.1101/2025.04.25.650731v1},
	doi = {10.1101/2025.04.25.650731},
	abstract = {Single-cell transcriptomics has revolutionized our understanding of cellular diversity, but integrating this knowledge across evolutionary distances remains challenging. Here we present TranscriptFormer, a family of generative foundation models representing a cross-species generative cell atlas trained on up to 112 million cells spanning 1.53 billion years of evolution across 12 species. TranscriptFormer jointly models genes and transcripts using a novel generative architecture, enabling it to function as a virtual instrument for probing cellular biology. In zero-shot settings, our models demonstrate superior performance on both in-distribution and out-of-distribution cell type classification, with robust performance even for species separated by over 685 million years of evolutionary distance. TranscriptFormer can also perform zero-shot disease state identification in human cells and accurately transfers cell type annotations across species boundaries. Being a generative model, TranscriptFormer can be prompted to predict cell type-specific transcription factors and gene-gene interactions that align with independent experimental observations. This work establishes a powerful framework for integrating and interrogating cellular diversity across species as well as offering a foundation for in silico experimentation with a generative single-cell atlas model.},
	language = {en},
	urldate = {2025-07-05},
	publisher = {bioRxiv},
	author = {Pearce, James D. and Simmonds, Sara E. and Mahmoudabadi, Gita and Krishnan, Lakshmi and Palla, Giovanni and Istrate, Ana-Maria and Tarashansky, Alexander and Nelson, Benjamin and Valenzuela, Omar and Li, Donghui and Quake, Stephen R. and Karaletsos, Theofanis},
	month = apr,
	year = {2025},
	note = {8 citations (Crossref/DOI) [2025-10-22]
Pages: 2025.04.25.650731
Section: New Results},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/MJ9SDFPY/2025-04-29 - Pearce et al. - [TranscriptFormer] Cross-Species Generative Cell Atlas Across 1.5 Billion Years of Evolution The Tr.pdf:application/pdf},
}

@article{theodoris_geneformer_2023,
	title = {[{Geneformer}] {Transfer} learning enables predictions in network biology},
	volume = {618},
	copyright = {2023 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-023-06139-9},
	doi = {10.1038/s41586-023-06139-9},
	abstract = {Mapping gene networks requires large amounts of transcriptomic data to learn the connections between genes, which impedes discoveries in settings with limited data, including rare diseases and diseases affecting clinically inaccessible tissues. Recently, transfer learning has revolutionized fields such as natural language understanding1,2 and computer vision3 by leveraging deep learning models pretrained on large-scale general datasets that can then be fine-tuned towards a vast array of downstream tasks with limited task-specific data. Here, we developed a context-aware, attention-based deep learning model, Geneformer, pretrained on a large-scale corpus of about 30 million single-cell transcriptomes to enable context-specific predictions in settings with limited data in network biology. During pretraining, Geneformer gained a fundamental understanding of network dynamics, encoding network hierarchy in the attention weights of the model in a completely self-supervised manner. Fine-tuning towards a diverse panel of downstream tasks relevant to chromatin and network dynamics using limited task-specific data demonstrated that Geneformer consistently boosted predictive accuracy. Applied to disease modelling with limited patient data, Geneformer identified candidate therapeutic targets for cardiomyopathy. Overall, Geneformer represents a pretrained deep learning model from which fine-tuning towards a broad range of downstream applications can be pursued to accelerate discovery of key network regulators and candidate therapeutic targets.},
	language = {en},
	number = {7965},
	urldate = {2025-09-13},
	journal = {Nature},
	author = {Theodoris, Christina V. and Xiao, Ling and Chopra, Anant and Chaffin, Mark D. and Al Sayed, Zeina R. and Hill, Matthew C. and Mantineo, Helene and Brydon, Elizabeth M. and Zeng, Zexian and Liu, X. Shirley and Ellinor, Patrick T.},
	month = may,
	year = {2023},
	note = {636 citations (Crossref/DOI) [2025-10-22]
Publisher: Nature Publishing Group},
	pages = {616--624},
	file = {Full Text PDF:/Users/meehl.joshua/Zotero/storage/RBXRGM2J/2023-06 - Theodoris et al. - Transfer learning enables predictions in network biology.pdf:application/pdf},
}

