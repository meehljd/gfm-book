# Instructions Compliance Report: DNA Language Models

**Source file:** `p3-ch11-dna-lm.qmd`  
**Reviewed against:** `claude-project-instructions.md`  
**Line count:** 253  

## Executive Summary

- **Blockers:** 2
- **Major issues:** 12
- **Minor issues:** 3

## Non-Negotiables Check

| Requirement | Status | Evidence |
|---|---|---|
| ZERO em-dashes (â€”) | PASS | 0 occurrence(s) |
| ZERO bullet points in prose | PASS | 0 markdown list item(s) detected |
| ZERO meta-commentary | FAIL | 1 flagged line(s) |
| Lead with Why | PASS | Opening starts with problem framing and stakes. |

## Issues

| Severity   | Rule                                                                  | Location                                                                                                                          | Evidence                                                                                                                                                                                                                                       | Recommendation                                                                                                 |
|:-----------|:----------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------|
| Blocker    | Output format must be markdown (.md), not .qmd                        | L1 (DNA Language Models)                                                                                                          | <code>p3-ch11-dna-lm.qmd</code>                                                                                                                                                                                                                | Convert the chapter deliverable to a .md file (do not output .qmd).                                            |
| Blocker    | ZERO meta-commentary / structural telegraphing                        | L7 (DNA Language Models)                                                                                                          | <code>The opportunity is substantial but not guaranteed to succeed. Protein *sequences* have clear functional units (domains, secondary structures ... probing studies, and assessing their performance across standardized benchmarks.</code> | Remove self-referential framing; state the content directly without narrating structure.                       |
| Major      | Avoid numbered lists disguised as prose (first/second/third patterns) | L23 (DNA Language Models > From Task-Specific CNNs to General-Purpose Language Models)                                            | <code>The practical workflow involves several steps. First, train a language model on unlabeled genomic sequences, where the model learns to predi ... becomes the default starting point for nearly any DNA-level prediction problem.</code>  | Rewrite as prose without explicit ordinal enumeration, or use a single colon sentence with parallel structure. |
| Major      | Citation key formatting: avoid backticks inside [@...] citations      | L28 (DNA Language Models > *DNABERT*: The First DNA Language Model)                                                               | <code>*DNABERT* applied the BERT **masked language modeling** framework to genomic sequences, establishing proof of concept for DNA self-supervisi ... ict masked tokens from surrounding context using the standard BERT architecture.</code> | Use standard citation syntax like [@avsec_enformer_2021] or in-prose 'Avsec et al. @avsec_enformer_2021'.      |
| Major      | Citation key formatting: avoid @`...` forms                           | L34 (DNA Language Models > *DNABERT*: The First DNA Language Model)                                                               | <code>**DNABERT*-2* addressed the tokenization limitations through improved approaches including BPE-style token merging that better compressed re ... s (see @sec-representations for detailed discussion of tokenization strategies).</code> | Remove backticks around citation keys.                                                                         |
| Major      | Citation key formatting: avoid backticks inside [@...] citations      | L52 (DNA Language Models > GPN: Cross-Species **Pretraining** for Variant Effect Prediction)                                      | <code>While the *Nucleotide Transformer* demonstrated the **value** of scaling, the **Genomic Pre-trained Network (*GPN*)** explored a complementa ... ision could yield useful variant effect predictors even in constrained settings.</code> | Use standard citation syntax like [@avsec_enformer_2021] or in-prose 'Avsec et al. @avsec_enformer_2021'.      |
| Major      | Citation key formatting: avoid backticks inside [@...] citations      | L77 (DNA Language Models > The Long-Context Revolution > *HyenaDNA*: Megabase Context via Implicit Convolutions)                  | <code>*HyenaDNA* addressed this limitation by replacing attention with implicit convolutions that scale sub-quadratically [@`nguyen_hyenadna_2023` ... * processes sequences up to 1 Mb while maintaining single-nucleotide resolution.</code> | Use standard citation syntax like [@avsec_enformer_2021] or in-prose 'Avsec et al. @avsec_enformer_2021'.      |
| Major      | Citation key formatting: avoid backticks inside [@...] citations      | L87 (DNA Language Models > The Long-Context Revolution > Caduceus: Bidirectional Processing with Reverse-Complement Equivariance) | <code>*Caduceus* addressed this challenge by building **reverse-complement equivariance** directly into the architecture [@`schiff_caduceus_2024`] ... mathematically related predictions for sequences and their reverse complements.</code>  | Use standard citation syntax like [@avsec_enformer_2021] or in-prose 'Avsec et al. @avsec_enformer_2021'.      |
| Major      | Citation key formatting: avoid backticks inside [@...] citations      | L93 (DNA Language Models > The Long-Context Revolution > Evo 2: Genome-Scale Modeling Across the Tree of Life)                    | <code>*Evo 2* represents the current frontier: training at genome scale across all domains of life [@`brixi_evo_2025`]. While previous models focu ... n universal genomic patterns spanning bacteria, archaea, eukaryotes, and phages.</code> | Use standard citation syntax like [@avsec_enformer_2021] or in-prose 'Avsec et al. @avsec_enformer_2021'.      |
| Major      | Citation key formatting: avoid backticks inside [@...] citations      | L174 (DNA Language Models > Benchmark Performance and Evaluation > Major Benchmark Suites)                                        | <code>**BEND (Benchmark for Nucleotide Deep learning)** provides a unified framework with tasks including gene *finding*, enhancer annotation, chr ... models capture biologically meaningful features at different resolution scales.</code>  | Use standard citation syntax like [@avsec_enformer_2021] or in-prose 'Avsec et al. @avsec_enformer_2021'.      |
| Major      | Citation key formatting: avoid backticks inside [@...] citations      | L178 (DNA Language Models > Benchmark Performance and Evaluation > Major Benchmark Suites)                                        | <code>**Long Range Benchmark (LRB)** and **DNALongBench** evaluate long-context modeling capabilities [@`cheng_dnalongbench_2024`]. Tasks include ... context architectures provide meaningful advantages over shorter-context models.</code>  | Use standard citation syntax like [@avsec_enformer_2021] or in-prose 'Avsec et al. @avsec_enformer_2021'.      |
| Major      | Citation key formatting: avoid backticks inside [@...] citations      | L180 (DNA Language Models > Benchmark Performance and Evaluation > Major Benchmark Suites)                                        | <code>Comparative evaluations across model families reveal that no single architecture dominates all tasks [@`manzo_comparative_2025`]. Performanc ... ; *Evo 2* shows advantages on cross-species tasks and variant effect prediction.</code> | Use standard citation syntax like [@avsec_enformer_2021] or in-prose 'Avsec et al. @avsec_enformer_2021'.      |
| Major      | Citation key formatting: avoid @`...` forms                           | L200 (DNA Language Models > Annotation-Aware Extensions)                                                                          | <code>**Life-Code** proposes central-dogma-informed tokenization, treating coding and noncoding regions differently [@`liu_life`-`code_2025`]. Cod ... encoding biological structure into tokenization provides useful inductive bias.</code>  | Remove backticks around citation keys.                                                                         |
| Major      | Citation key formatting: avoid backticks inside [@...] citations      | L202 (DNA Language Models > Annotation-Aware Extensions)                                                                          | <code>**BioToken** extends tokenization to include explicit genomic annotations [@`medvedev_biotoken_2025`]. Rather than representing regions pure ... , suggesting that annotation-aware representations improve parameter efficiency.</code> | Use standard citation syntax like [@avsec_enformer_2021] or in-prose 'Avsec et al. @avsec_enformer_2021'.      |
| Minor      | Avoid false enthusiasm / marketing tone                               | L11 (DNA Language Models > From Task-Specific CNNs to General-Purpose Language Models)                                            | <code>The convolutional neural networks examined in @sec-cnn achieved remarkable performance on specific genomic prediction tasks. DeepSEA predict ... er sizes, dilation patterns, pooling strategies) optimized for the task at hand.</code> | Use neutral academic phrasing; attribute assessments to sources if needed.                                     |
| Minor      | Avoid false enthusiasm / marketing tone                               | L23 (DNA Language Models > From Task-Specific CNNs to General-Purpose Language Models)                                            | <code>The practical workflow involves several steps. First, train a language model on unlabeled genomic sequences, where the model learns to predi ... becomes the default starting point for nearly any DNA-level prediction problem.</code>  | Use neutral academic phrasing; attribute assessments to sources if needed.                                     |
| Minor      | Avoid anthropomorphization                                            | L109 (DNA Language Models > The Long-Context Revolution > Evo 2: Genome-Scale Modeling Across the Tree of Life)                   | <code>*Evo 2* exhibits several forms of emergent biological knowledge despite training only on raw sequence. The model learns to identify exon-int ... ting that genome-scale pretraining captures fundamental biological organization.</code> | Rephrase in operational terms (predict, represent, encode, optimize) rather than cognition verbs.              |

## Notes for Downstream LLM

- Treat **Blockers** as required edits for this chapter to be instruction-compliant.
- Many issues are mechanical and can be fixed by systematic search-and-replace (for example, citation-key backticks).
