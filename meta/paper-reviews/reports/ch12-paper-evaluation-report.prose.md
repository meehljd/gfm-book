# Chapter 12 — Paper evaluation report (prose)

Processed in alphabetical order by citation key. Date: 2025-12-22.


### abramson_alphafold3_2024

[AlphaFold3] Accurate structure prediction of biomolecular interactions with AlphaFold 3 — Abramson, Josh and Adler, Jonas and Dunger, Jack and Evans, Richard and Green, Tim and Pritzel, Alexander and Ronneberger, Olaf and Willmore, Lindsay and Ballard, Andrew J. and Bambrick, Joshua and Bodenstein, Sebastian W. and Evans, David A. and Hung, Chia-Chun and O’Neill, Michael and Reiman, David and Tunyasuvunakool, Kathryn and Wu, Zachary and Žemgulytė, Akvilė and Arvaniti, Eirini and Beattie, Charles and Bertolli, Ottavia and Bridgland, Alex and Cherepanov, Alexey and Congreve, Miles and Cowen-Rivers, Alexander I. and Cowie, Andrew and Figurnov, Michael and Fuchs, Fabian B. and Gladman, Hannah and Jain, Rishub and Khan, Yousuf A. and Low, Caroline M. R. and Perlin, Kuba and Potapenko, Anna and Savy, Pascal and Singh, Sukhdeep and Stecula, Adrian and Thillaisundaram, Ashok and Tong, Catherine and Yakneen, Sergei and Zhong, Ellen D. and Zielinski, Michal and Žídek, Augustin and Bapst, Victor and Kohli, Pushmeet and Jaderberg, Max and Hassabis, Demis and Jumper, John M. — Nature (2024) — DOI: 10.1038/s41586-024-07487-w — URL: https://www.nature.com/articles/s41586-024-07487-w

**Scope fit.** This work is in-scope for the book: it applies deep learning to biological sequences (protein), with direct relevance to genomic/protein foundation models or downstream tasks.

**Recency relevance.** This is recent/modern work (year 2024), aligned with current genomic foundation-model approaches.

**Venue signal.** The venue given in the BibTeX entry is Nature. This is generally a credible signal, but final confidence depends on confirming the version-of-record (especially if the entry is a preprint).

**Tier 1 red flags.** No immediate red flags are visible from bibliographic metadata alone. However, the framework’s highest-risk failure modes (data leakage, weak baselines, missing held-out evaluation, circular validation) require checking the paper PDF and supplementary methods.

**Reproducibility (0–3): 2.** This line of work commonly provides sufficient methodological detail and/or some artifacts (code, models, or datasets), but this should be confirmed in the PDF and associated repositories.

**Validation rigor (0–3): 2.** Validation is likely reasonably rigorous (multiple benchmarks or tasks), though the independence of test sets should be verified.

**Claim calibration.** No obvious over-claiming is detectable from the citation metadata alone; confirm by reading the abstract/results to ensure claims match evidence.

**Book relevance (gap filled).** This paper likely supports a core concept, model family, benchmark, or deployment-relevant application that the textbook should teach explicitly.

**Integration cost.** Integration cost: moderate. Recommend adding a short boxed example/figure plus a citation, and referencing it in the relevant chapter narrative.

**Pedagogical value.** Moderate pedagogical value: useful concept, but may require careful framing or simplification.

**Longevity.** Longevity uncertain; adoption and replication should be monitored.

**PDF availability.** Publisher PDF via DOI (may be paywalled).

**Recommendation.** INCLUDE. Suggested book location: Ch12 (protein models/variant effects).


---

### brandes_genome-wide_2023

Genome-wide prediction of disease variant effects with a deep protein language model — Brandes, Nadav and Goldman, Grant and Wang, Charlotte H. and Ye, Chun Jimmie and Ntranos, Vasilis — Nature Genetics (2023) — DOI: 10.1038/s41588-023-01465-0 — URL: https://www.nature.com/articles/s41588-023-01465-0

**Scope fit.** This work is in-scope for the book: it applies deep learning to biological sequences (genomics), with direct relevance to genomic/protein foundation models or downstream tasks.

**Recency relevance.** This is recent/modern work (year 2023), aligned with current genomic foundation-model approaches.

**Venue signal.** The venue given in the BibTeX entry is Nature Genetics. This is generally a credible signal, but final confidence depends on confirming the version-of-record (especially if the entry is a preprint).

**Tier 1 red flags.** No immediate red flags are visible from bibliographic metadata alone. However, the framework’s highest-risk failure modes (data leakage, weak baselines, missing held-out evaluation, circular validation) require checking the paper PDF and supplementary methods.

**Reproducibility (0–3): 2.** This line of work commonly provides sufficient methodological detail and/or some artifacts (code, models, or datasets), but this should be confirmed in the PDF and associated repositories.

**Validation rigor (0–3): 2.** Validation is likely reasonably rigorous (multiple benchmarks or tasks), though the independence of test sets should be verified.

**Claim calibration.** No obvious over-claiming is detectable from the citation metadata alone; confirm by reading the abstract/results to ensure claims match evidence.

**Book relevance (gap filled).** This paper likely supports a core concept, model family, benchmark, or deployment-relevant application that the textbook should teach explicitly.

**Integration cost.** Integration cost: moderate. Recommend adding a short boxed example/figure plus a citation, and referencing it in the relevant chapter narrative.

**Pedagogical value.** High pedagogical value: clean principle or widely-reused method with teachable examples/figures.

**Longevity.** Likely to remain relevant (‘textbook test’ passes).

**PDF availability.** Publisher PDF via DOI (may be paywalled).

**Recommendation.** INCLUDE. Suggested book location: Ch12 (genomic sequence modeling).


---

### cheng_alphamissense_2023

[AlphaMissense] Accurate proteome-wide missense variant effect prediction with AlphaMissense — Cheng, Jun and Novati, Guido and Pan, Joshua and Bycroft, Clare and Žemgulytė, Akvilė and Applebaum, Taylor and Pritzel, Alexander and Wong, Lai Hong and Zielinski, Michal and Sargeant, Tobias and Schneider, Rosalia G. and Senior, Andrew W. and Jumper, John and Hassabis, Demis and Kohli, Pushmeet and Avsec, Žiga — Science (2023) — DOI: 10.1126/science.adg7492 — URL: https://www.science.org/doi/full/10.1126/science.adg7492

**Scope fit.** This work is in-scope for the book: it applies deep learning to biological sequences (genomics), with direct relevance to genomic/protein foundation models or downstream tasks.

**Recency relevance.** This is recent/modern work (year 2023), aligned with current genomic foundation-model approaches.

**Venue signal.** The venue given in the BibTeX entry is Science. This is generally a credible signal, but final confidence depends on confirming the version-of-record (especially if the entry is a preprint).

**Tier 1 red flags.** No immediate red flags are visible from bibliographic metadata alone. However, the framework’s highest-risk failure modes (data leakage, weak baselines, missing held-out evaluation, circular validation) require checking the paper PDF and supplementary methods.

**Reproducibility (0–3): 1.** Reproducibility is unclear from the citation metadata; assume methods-only unless the PDF provides code/data/weights.

**Validation rigor (0–3): 3.** Validation is likely strong (broad benchmarks and/or large-scale/clinical-style evaluation), but details and leakage controls should be checked in the PDF.

**Claim calibration.** No obvious over-claiming is detectable from the citation metadata alone; confirm by reading the abstract/results to ensure claims match evidence.

**Book relevance (gap filled).** This paper likely supports a core concept, model family, benchmark, or deployment-relevant application that the textbook should teach explicitly.

**Integration cost.** Integration cost: moderate. Recommend adding a short boxed example/figure plus a citation, and referencing it in the relevant chapter narrative.

**Pedagogical value.** High pedagogical value: clean principle or widely-reused method with teachable examples/figures.

**Longevity.** Likely to remain relevant (‘textbook test’ passes).

**PDF availability.** Publisher PDF via DOI (may be paywalled).

**Recommendation.** INCLUDE. Suggested book location: Ch12 (genomic sequence modeling).


---

### dauparas_proteinmpnn_2022

Robust deep learning–based protein sequence design using ProteinMPNN — Dauparas, J. and Anishchenko, I. and Bennett, N. and Bai, H. and Ragotte, R. J. and Milles, L. F. and Wicky, B. I. M. and Courbet, A. and de Haas, R. J. and Bethel, N. and Leung, P. J. Y. and Huddy, T. F. and Pellock, S. and Tischer, D. and Chan, F. and Koepnick, B. and Nguyen, H. and Kang, A. and Sankaran, B. and Bera, A. K. and King, N. P. and Baker, D. — Science (2022) — DOI: 10.1126/science.add2187 — URL: https://www.science.org/doi/10.1126/science.add2187

**Scope fit.** This work is in-scope for the book: it applies deep learning to biological sequences (protein), with direct relevance to genomic/protein foundation models or downstream tasks.

**Recency relevance.** This is recent/modern work (year 2022), aligned with current genomic foundation-model approaches.

**Venue signal.** The venue given in the BibTeX entry is Science. This is generally a credible signal, but final confidence depends on confirming the version-of-record (especially if the entry is a preprint).

**Tier 1 red flags.** No immediate red flags are visible from bibliographic metadata alone. However, the framework’s highest-risk failure modes (data leakage, weak baselines, missing held-out evaluation, circular validation) require checking the paper PDF and supplementary methods.

**Reproducibility (0–3): 2.** This line of work commonly provides sufficient methodological detail and/or some artifacts (code, models, or datasets), but this should be confirmed in the PDF and associated repositories.

**Validation rigor (0–3): 2.** Validation is likely reasonably rigorous (multiple benchmarks or tasks), though the independence of test sets should be verified.

**Claim calibration.** No obvious over-claiming is detectable from the citation metadata alone; confirm by reading the abstract/results to ensure claims match evidence.

**Book relevance (gap filled).** This paper likely supports a core concept, model family, benchmark, or deployment-relevant application that the textbook should teach explicitly.

**Integration cost.** Integration cost: moderate. Recommend adding a short boxed example/figure plus a citation, and referencing it in the relevant chapter narrative.

**Pedagogical value.** Moderate pedagogical value: useful concept, but may require careful framing or simplification.

**Longevity.** Likely to remain relevant (‘textbook test’ passes).

**PDF availability.** Publisher PDF via DOI (may be paywalled).

**Recommendation.** INCLUDE. Suggested book location: Ch12 (protein models/variant effects).


---

### elnaggar_prottrans_2021

ProtTrans: Towards Cracking the Language of Life's Code Through Self-Supervised Deep Learning and High Performance Computing — Elnaggar, Ahmed and Heinzinger, Michael and Dallago, Christian and Rihawi, Ghalia and Wang, Yu and Jones, Llion and Gibbs, Tom and Feher, Tamas and Angerer, Christoph and Steinegger, Martin and Bhowmik, Debsindhu and Rost, Burkhard — arXiv (2021) — DOI: 10.48550/arXiv.2007.06225 — URL: http://arxiv.org/abs/2007.06225

**Scope fit.** Scope fit is unclear from the BibTeX metadata alone; the title/venue do not unambiguously signal deep learning over genomic or protein sequences.

**Recency relevance.** This is mid-era work (year 2021) that often serves as a bridge between early deep learning for sequences and modern foundation models.

**Venue signal.** The BibTeX entry does not specify a venue (journal/conference). This weakens venue signal until a version-of-record is confirmed. Preprint/published-status check: Published version: IEEE TPAMI (2022).

**Tier 1 red flags.** No immediate red flags are visible from bibliographic metadata alone. However, the framework’s highest-risk failure modes (data leakage, weak baselines, missing held-out evaluation, circular validation) require checking the paper PDF and supplementary methods.

**Reproducibility (0–3): 1.** Reproducibility is unclear from the citation metadata; assume methods-only unless the PDF provides code/data/weights.

**Validation rigor (0–3): 1.** Validation is likely limited (e.g., single benchmark or closely related datasets), pending PDF verification.

**Claim calibration.** No obvious over-claiming is detectable from the citation metadata alone; confirm by reading the abstract/results to ensure claims match evidence.

**Book relevance (gap filled).** This paper is useful as supporting/background material rather than a centerpiece.

**Integration cost.** Integration cost: low. A brief citation (and possibly a one-sentence pointer) is usually sufficient.

**Pedagogical value.** Moderate pedagogical value: useful concept, but may require careful framing or simplification.

**Longevity.** Longevity uncertain; adoption and replication should be monitored.

**PDF availability.** Likely public PDF via preprint server.

**Recommendation.** CITED. Suggested book location: Ch12.


---

### jumper_alphafold2_2021

[AlphaFold2] Highly accurate protein structure prediction with AlphaFold — Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and Žídek, Augustin and Potapenko, Anna and Bridgland, Alex and Meyer, Clemens and Kohl, Simon A. A. and Ballard, Andrew J. and Cowie, Andrew and Romera-Paredes, Bernardino and Nikolov, Stanislav and Jain, Rishub and Adler, Jonas and Back, Trevor and Petersen, Stig and Reiman, David and Clancy, Ellen and Zielinski, Michal and Steinegger, Martin and Pacholska, Michalina and Berghammer, Tamas and Bodenstein, Sebastian and Silver, David and Vinyals, Oriol and Senior, Andrew W. and Kavukcuoglu, Koray and Kohli, Pushmeet and Hassabis, Demis — Nature (2021) — DOI: 10.1038/s41586-021-03819-2

**Scope fit.** This work is in-scope for the book: it applies deep learning to biological sequences (protein), with direct relevance to genomic/protein foundation models or downstream tasks.

**Recency relevance.** This is mid-era work (year 2021) that often serves as a bridge between early deep learning for sequences and modern foundation models.

**Venue signal.** The venue given in the BibTeX entry is Nature. This is generally a credible signal, but final confidence depends on confirming the version-of-record (especially if the entry is a preprint).

**Tier 1 red flags.** No immediate red flags are visible from bibliographic metadata alone. However, the framework’s highest-risk failure modes (data leakage, weak baselines, missing held-out evaluation, circular validation) require checking the paper PDF and supplementary methods.

**Reproducibility (0–3): 2.** This line of work commonly provides sufficient methodological detail and/or some artifacts (code, models, or datasets), but this should be confirmed in the PDF and associated repositories.

**Validation rigor (0–3): 2.** Validation is likely reasonably rigorous (multiple benchmarks or tasks), though the independence of test sets should be verified.

**Claim calibration.** No obvious over-claiming is detectable from the citation metadata alone; confirm by reading the abstract/results to ensure claims match evidence.

**Book relevance (gap filled).** This paper likely supports a core concept, model family, benchmark, or deployment-relevant application that the textbook should teach explicitly.

**Integration cost.** Integration cost: moderate. Recommend adding a short boxed example/figure plus a citation, and referencing it in the relevant chapter narrative.

**Pedagogical value.** Moderate pedagogical value: useful concept, but may require careful framing or simplification.

**Longevity.** Likely to remain relevant (‘textbook test’ passes).

**PDF availability.** Publisher PDF via DOI (may be paywalled).

**Recommendation.** INCLUDE. Suggested book location: Ch12 (protein models/variant effects).


---

### lin_esm-2_2022

[ESM-2] Language models of protein sequences at the scale of evolution enable accurate structure prediction — Lin, Zeming and Akin, Halil and Rao, Roshan and Hie, Brian and Zhu, Zhongkai and Lu, Wenting and Costa, Allan dos Santos and Fazel-Zarandi, Maryam and Sercu, Tom and Candido, Sal and Rives, Alexander — bioRxiv (2022) — DOI: 10.1101/2022.07.20.500902 — URL: https://www.biorxiv.org/content/10.1101/2022.07.20.500902v1

**Scope fit.** This work is in-scope for the book: it applies deep learning to biological sequences (protein), with direct relevance to genomic/protein foundation models or downstream tasks.

**Recency relevance.** This is recent/modern work (year 2022), aligned with current genomic foundation-model approaches.

**Venue signal.** The BibTeX entry does not specify a venue (journal/conference). This weakens venue signal until a version-of-record is confirmed. Preprint/published-status check: Published version: Science (2023) via ESMFold/ESM-2 line of work.

**Tier 1 red flags.** No immediate red flags are visible from bibliographic metadata alone. However, the framework’s highest-risk failure modes (data leakage, weak baselines, missing held-out evaluation, circular validation) require checking the paper PDF and supplementary methods.

**Reproducibility (0–3): 2.** This line of work commonly provides sufficient methodological detail and/or some artifacts (code, models, or datasets), but this should be confirmed in the PDF and associated repositories.

**Validation rigor (0–3): 2.** Validation is likely reasonably rigorous (multiple benchmarks or tasks), though the independence of test sets should be verified.

**Claim calibration.** No obvious over-claiming is detectable from the citation metadata alone; confirm by reading the abstract/results to ensure claims match evidence.

**Book relevance (gap filled).** This paper likely supports a core concept, model family, benchmark, or deployment-relevant application that the textbook should teach explicitly.

**Integration cost.** Integration cost: moderate. Recommend adding a short boxed example/figure plus a citation, and referencing it in the relevant chapter narrative.

**Pedagogical value.** Moderate pedagogical value: useful concept, but may require careful framing or simplification.

**Longevity.** Likely to remain relevant (‘textbook test’ passes).

**PDF availability.** Likely public PDF via preprint server.

**Recommendation.** INCLUDE. Suggested book location: Ch12 (protein models/variant effects).


---

### meier_esm-1v_2021

[ESM-1v] Language models enable zero-shot prediction of the effects of mutations on protein function — Meier, Joshua and Rao, Roshan and Verkuil, Robert and Liu, Jason and Sercu, Tom and Rives, Alexander — bioRxiv (2021) — DOI: 10.1101/2021.07.09.450648 — URL: https://www.biorxiv.org/content/10.1101/2021.07.09.450648v1

**Scope fit.** This work is in-scope for the book: it applies deep learning to biological sequences (protein), with direct relevance to genomic/protein foundation models or downstream tasks.

**Recency relevance.** This is mid-era work (year 2021) that often serves as a bridge between early deep learning for sequences and modern foundation models.

**Venue signal.** The BibTeX entry does not specify a venue (journal/conference). This weakens venue signal until a version-of-record is confirmed. Preprint/published-status check: Published version: NeurIPS 2021 (same title).

**Tier 1 red flags.** No immediate red flags are visible from bibliographic metadata alone. However, the framework’s highest-risk failure modes (data leakage, weak baselines, missing held-out evaluation, circular validation) require checking the paper PDF and supplementary methods.

**Reproducibility (0–3): 2.** This line of work commonly provides sufficient methodological detail and/or some artifacts (code, models, or datasets), but this should be confirmed in the PDF and associated repositories.

**Validation rigor (0–3): 2.** Validation is likely reasonably rigorous (multiple benchmarks or tasks), though the independence of test sets should be verified.

**Claim calibration.** No obvious over-claiming is detectable from the citation metadata alone; confirm by reading the abstract/results to ensure claims match evidence.

**Book relevance (gap filled).** This paper likely supports a core concept, model family, benchmark, or deployment-relevant application that the textbook should teach explicitly.

**Integration cost.** Integration cost: moderate. Recommend adding a short boxed example/figure plus a citation, and referencing it in the relevant chapter narrative.

**Pedagogical value.** Moderate pedagogical value: useful concept, but may require careful framing or simplification.

**Longevity.** Likely to remain relevant (‘textbook test’ passes).

**PDF availability.** Likely public PDF via preprint server.

**Recommendation.** INCLUDE. Suggested book location: Ch12 (protein models/variant effects).


---

### morcos_dca_2011

Direct-coupling analysis of residue coevolution captures native contacts across many protein families — (2011)

**Scope fit.** This work is in-scope for the book: it applies deep learning to biological sequences (protein), with direct relevance to genomic/protein foundation models or downstream tasks.

**Recency relevance.** This is a foundational paper (year 2011) that remains influential and is still commonly cited in modern foundation-model practice.

**Venue signal.** The BibTeX entry does not specify a venue (journal/conference). This weakens venue signal until a version-of-record is confirmed.

**Tier 1 red flags.** No immediate red flags are visible from bibliographic metadata alone. However, the framework’s highest-risk failure modes (data leakage, weak baselines, missing held-out evaluation, circular validation) require checking the paper PDF and supplementary methods.

**Reproducibility (0–3): 2.** This line of work commonly provides sufficient methodological detail and/or some artifacts (code, models, or datasets), but this should be confirmed in the PDF and associated repositories.

**Validation rigor (0–3): 2.** Validation is likely reasonably rigorous (multiple benchmarks or tasks), though the independence of test sets should be verified.

**Claim calibration.** No obvious over-claiming is detectable from the citation metadata alone; confirm by reading the abstract/results to ensure claims match evidence.

**Book relevance (gap filled).** This paper likely supports a core concept, model family, benchmark, or deployment-relevant application that the textbook should teach explicitly.

**Integration cost.** Integration cost: moderate. Recommend adding a short boxed example/figure plus a citation, and referencing it in the relevant chapter narrative.

**Pedagogical value.** Moderate pedagogical value: useful concept, but may require careful framing or simplification.

**Longevity.** Likely to remain relevant (‘textbook test’ passes).

**PDF availability.** PDF not identifiable from BibTeX metadata.

**Recommendation.** INCLUDE. Suggested book location: Ch12 (protein models/variant effects).


---

### raffel_t5_2019

Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer — Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J. — arXiv (2019) — DOI: 10.48550/arXiv.1910.10683 — URL: http://arxiv.org/abs/1910.10683

**Scope fit.** This paper is not genomics-specific, but it is relevant background: it introduces or analyzes a general deep learning method (e.g., Transformers, scaling laws, parameter-efficient fine-tuning, or calibration) that is widely reused in genomic foundation models.

**Recency relevance.** This is a foundational paper (year 2019) that remains influential and is still commonly cited in modern foundation-model practice.

**Venue signal.** The BibTeX entry does not specify a venue (journal/conference). This weakens venue signal until a version-of-record is confirmed. Preprint/published-status check: Published version: JMLR (2020).

**Tier 1 red flags.** No immediate red flags are visible from bibliographic metadata alone. However, the framework’s highest-risk failure modes (data leakage, weak baselines, missing held-out evaluation, circular validation) require checking the paper PDF and supplementary methods.

**Reproducibility (0–3): 2.** This line of work commonly provides sufficient methodological detail and/or some artifacts (code, models, or datasets), but this should be confirmed in the PDF and associated repositories.

**Validation rigor (0–3): 1.** Validation is likely limited (e.g., single benchmark or closely related datasets), pending PDF verification.

**Claim calibration.** No obvious over-claiming is detectable from the citation metadata alone; confirm by reading the abstract/results to ensure claims match evidence.

**Book relevance (gap filled).** This paper is useful as supporting/background material rather than a centerpiece.

**Integration cost.** Integration cost: low. A brief citation (and possibly a one-sentence pointer) is usually sufficient.

**Pedagogical value.** Lower pedagogical value: mostly background or incremental, best kept as a citation only.

**Longevity.** Likely to remain relevant (‘textbook test’ passes).

**PDF availability.** Likely public PDF via preprint server.

**Recommendation.** CITED. Suggested book location: Ch12 (methods background).


---

### rao_transformer_2020

Transformer protein language models are unsupervised structure learners — Rao, Roshan and Meier, Joshua and Sercu, Tom and Ovchinnikov, Sergey and Rives, Alexander — bioRxiv (2020) — DOI: 10.1101/2020.12.15.422761 — URL: https://www.biorxiv.org/content/10.1101/2020.12.15.422761v1

**Scope fit.** This work is in-scope for the book: it applies deep learning to biological sequences (protein), with direct relevance to genomic/protein foundation models or downstream tasks.

**Recency relevance.** This is mid-era work (year 2020) that often serves as a bridge between early deep learning for sequences and modern foundation models.

**Venue signal.** The BibTeX entry does not specify a venue (journal/conference). This weakens venue signal until a version-of-record is confirmed. Preprint/published-status check: Published version: ICML 2021 (MSA Transformer).

**Tier 1 red flags.** No immediate red flags are visible from bibliographic metadata alone. However, the framework’s highest-risk failure modes (data leakage, weak baselines, missing held-out evaluation, circular validation) require checking the paper PDF and supplementary methods.

**Reproducibility (0–3): 2.** This line of work commonly provides sufficient methodological detail and/or some artifacts (code, models, or datasets), but this should be confirmed in the PDF and associated repositories.

**Validation rigor (0–3): 2.** Validation is likely reasonably rigorous (multiple benchmarks or tasks), though the independence of test sets should be verified.

**Claim calibration.** No obvious over-claiming is detectable from the citation metadata alone; confirm by reading the abstract/results to ensure claims match evidence.

**Book relevance (gap filled).** This paper likely supports a core concept, model family, benchmark, or deployment-relevant application that the textbook should teach explicitly.

**Integration cost.** Integration cost: moderate. Recommend adding a short boxed example/figure plus a citation, and referencing it in the relevant chapter narrative.

**Pedagogical value.** Moderate pedagogical value: useful concept, but may require careful framing or simplification.

**Longevity.** Likely to remain relevant (‘textbook test’ passes).

**PDF availability.** Likely public PDF via preprint server.

**Recommendation.** INCLUDE. Suggested book location: Ch12 (protein models/variant effects).


---

### rives_esm_2021

[ESM-1b] Biological structure and function emerge from scaling unsupervised learning to 250 million protein sequences — Rives, Alexander and Meier, Joshua and Sercu, Tom and Goyal, Siddharth and Lin, Zeming and Liu, Jason and Guo, Demi and Ott, Myle and Zitnick, C. Lawrence and Ma, Jerry and Fergus, Rob — Proceedings of the National Academy of Sciences of the United States of America (2021) — DOI: 10.1073/pnas.2016239118

**Scope fit.** This work is in-scope for the book: it applies deep learning to biological sequences (protein), with direct relevance to genomic/protein foundation models or downstream tasks.

**Recency relevance.** This is mid-era work (year 2021) that often serves as a bridge between early deep learning for sequences and modern foundation models.

**Venue signal.** The venue given in the BibTeX entry is Proceedings of the National Academy of Sciences of the United States of America. This is generally a credible signal, but final confidence depends on confirming the version-of-record (especially if the entry is a preprint).

**Tier 1 red flags.** No immediate red flags are visible from bibliographic metadata alone. However, the framework’s highest-risk failure modes (data leakage, weak baselines, missing held-out evaluation, circular validation) require checking the paper PDF and supplementary methods.

**Reproducibility (0–3): 2.** This line of work commonly provides sufficient methodological detail and/or some artifacts (code, models, or datasets), but this should be confirmed in the PDF and associated repositories.

**Validation rigor (0–3): 2.** Validation is likely reasonably rigorous (multiple benchmarks or tasks), though the independence of test sets should be verified.

**Claim calibration.** No obvious over-claiming is detectable from the citation metadata alone; confirm by reading the abstract/results to ensure claims match evidence.

**Book relevance (gap filled).** This paper likely supports a core concept, model family, benchmark, or deployment-relevant application that the textbook should teach explicitly.

**Integration cost.** Integration cost: moderate. Recommend adding a short boxed example/figure plus a citation, and referencing it in the relevant chapter narrative.

**Pedagogical value.** Moderate pedagogical value: useful concept, but may require careful framing or simplification.

**Longevity.** Likely to remain relevant (‘textbook test’ passes).

**PDF availability.** Publisher PDF via DOI (may be paywalled).

**Recommendation.** INCLUDE. Suggested book location: Ch12 (protein models/variant effects).


---

### suzek_uniref_2007

UniRef: comprehensive and non-redundant UniProt reference clusters — Suzek, Baris E. and Huang, Hongzhan and McGarvey, Peter and Mazumder, Raja and Wu, Cathy H. — Bioinformatics (2007) — DOI: 10.1093/bioinformatics/btm098 — URL: https://doi.org/10.1093/bioinformatics/btm098

**Scope fit.** Scope fit is unclear from the BibTeX metadata alone; the title/venue do not unambiguously signal deep learning over genomic or protein sequences.

**Recency relevance.** This is a foundational paper (year 2007) that remains influential and is still commonly cited in modern foundation-model practice.

**Venue signal.** The venue given in the BibTeX entry is Bioinformatics. This is generally a credible signal, but final confidence depends on confirming the version-of-record (especially if the entry is a preprint).

**Tier 1 red flags.** No immediate red flags are visible from bibliographic metadata alone. However, the framework’s highest-risk failure modes (data leakage, weak baselines, missing held-out evaluation, circular validation) require checking the paper PDF and supplementary methods.

**Reproducibility (0–3): 1.** Reproducibility is unclear from the citation metadata; assume methods-only unless the PDF provides code/data/weights.

**Validation rigor (0–3): 1.** Validation is likely limited (e.g., single benchmark or closely related datasets), pending PDF verification.

**Claim calibration.** No obvious over-claiming is detectable from the citation metadata alone; confirm by reading the abstract/results to ensure claims match evidence.

**Book relevance (gap filled).** This paper is useful as supporting/background material rather than a centerpiece.

**Integration cost.** Integration cost: low. A brief citation (and possibly a one-sentence pointer) is usually sufficient.

**Pedagogical value.** Moderate pedagogical value: useful concept, but may require careful framing or simplification.

**Longevity.** Longevity uncertain; adoption and replication should be monitored.

**PDF availability.** Publisher PDF via DOI (may be paywalled).

**Recommendation.** CITED. Suggested book location: Ch12.


---

### watson_rfdiffusion_2023

De novo design of protein structure and function with RFdiffusion — Watson, Joseph L. and Juergens, David and Bennett, Nathaniel R. and Trippe, Brian L. and Yim, Jason and Eisenach, Helen E. and Ahern, Woody and Borst, Andrew J. and Ragotte, Robert J. and Milles, Lukas F. and Wicky, Basile I. M. and Hanikel, Nikita and Pellock, Samuel J. and Courbet, Alexis and Sheffler, William and Wang, Jue and Venkatesh, Preetham and Sappington, Isaac and Torres, Susana Vázquez and Lauko, Anna and De Bortoli, Valentin and Mathieu, Emile and Ovchinnikov, Sergey and Barzilay, Regina and Jaakkola, Tommi S. and DiMaio, Frank and Baek, Minkyung and Baker, David — Nature (2023) — DOI: 10.1038/s41586-023-06415-8 — URL: https://www.nature.com/articles/s41586-023-06415-8

**Scope fit.** This work is in-scope for the book: it applies deep learning to biological sequences (protein), with direct relevance to genomic/protein foundation models or downstream tasks.

**Recency relevance.** This is recent/modern work (year 2023), aligned with current genomic foundation-model approaches.

**Venue signal.** The venue given in the BibTeX entry is Nature. This is generally a credible signal, but final confidence depends on confirming the version-of-record (especially if the entry is a preprint).

**Tier 1 red flags.** No immediate red flags are visible from bibliographic metadata alone. However, the framework’s highest-risk failure modes (data leakage, weak baselines, missing held-out evaluation, circular validation) require checking the paper PDF and supplementary methods.

**Reproducibility (0–3): 2.** This line of work commonly provides sufficient methodological detail and/or some artifacts (code, models, or datasets), but this should be confirmed in the PDF and associated repositories.

**Validation rigor (0–3): 2.** Validation is likely reasonably rigorous (multiple benchmarks or tasks), though the independence of test sets should be verified.

**Claim calibration.** No obvious over-claiming is detectable from the citation metadata alone; confirm by reading the abstract/results to ensure claims match evidence.

**Book relevance (gap filled).** This paper likely supports a core concept, model family, benchmark, or deployment-relevant application that the textbook should teach explicitly.

**Integration cost.** Integration cost: moderate. Recommend adding a short boxed example/figure plus a citation, and referencing it in the relevant chapter narrative.

**Pedagogical value.** Moderate pedagogical value: useful concept, but may require careful framing or simplification.

**Longevity.** Likely to remain relevant (‘textbook test’ passes).

**PDF availability.** Publisher PDF via DOI (may be paywalled).

**Recommendation.** INCLUDE. Suggested book location: Ch12 (protein models/variant effects).


---

### yang_xlnet_2020

XLNet: Generalized Autoregressive Pretraining for Language Understanding — Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Ruslan and Le, Quoc V. — arXiv (2020) — DOI: 10.48550/arXiv.1906.08237 — URL: http://arxiv.org/abs/1906.08237

**Scope fit.** This work is in-scope for the book: it applies deep learning to biological sequences (genomics), with direct relevance to genomic/protein foundation models or downstream tasks.

**Recency relevance.** This is mid-era work (year 2020) that often serves as a bridge between early deep learning for sequences and modern foundation models.

**Venue signal.** The BibTeX entry does not specify a venue (journal/conference). This weakens venue signal until a version-of-record is confirmed. Preprint/published-status check: Published version: NeurIPS (2019).

**Tier 1 red flags.** No immediate red flags are visible from bibliographic metadata alone. However, the framework’s highest-risk failure modes (data leakage, weak baselines, missing held-out evaluation, circular validation) require checking the paper PDF and supplementary methods.

**Reproducibility (0–3): 2.** This line of work commonly provides sufficient methodological detail and/or some artifacts (code, models, or datasets), but this should be confirmed in the PDF and associated repositories.

**Validation rigor (0–3): 2.** Validation is likely reasonably rigorous (multiple benchmarks or tasks), though the independence of test sets should be verified.

**Claim calibration.** No obvious over-claiming is detectable from the citation metadata alone; confirm by reading the abstract/results to ensure claims match evidence.

**Book relevance (gap filled).** This paper likely supports a core concept, model family, benchmark, or deployment-relevant application that the textbook should teach explicitly.

**Integration cost.** Integration cost: moderate. Recommend adding a short boxed example/figure plus a citation, and referencing it in the relevant chapter narrative.

**Pedagogical value.** Moderate pedagogical value: useful concept, but may require careful framing or simplification.

**Longevity.** Likely to remain relevant (‘textbook test’ passes).

**PDF availability.** Likely public PDF via preprint server.

**Recommendation.** INCLUDE. Suggested book location: Ch12 (genomic sequence modeling).


---
