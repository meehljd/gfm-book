# Chapter 05 — Paper evaluation report (prose)

Processed in alphabetical order by citation key. Date: 2025-12-22.


### ji_dnabert_2021

DNABERT: pre-trained Bidirectional Encoder Representations from Transformers model for DNA-language in genome — Ji, Yanrong and Zhou, Zhihan and Liu, Han and Davuluri, Ramana V — Bioinformatics (2021) — DOI: 10.1093/bioinformatics/btab083 — URL: https://doi.org/10.1093/bioinformatics/btab083

**Scope fit.** This work is in-scope for the book: it applies deep learning to biological sequences (genomics), with direct relevance to genomic/protein foundation models or downstream tasks.

**Recency relevance.** This is mid-era work (year 2021) that often serves as a bridge between early deep learning for sequences and modern foundation models.

**Venue signal.** The venue given in the BibTeX entry is Bioinformatics. This is generally a credible signal, but final confidence depends on confirming the version-of-record (especially if the entry is a preprint).

**Tier 1 red flags.** No immediate red flags are visible from bibliographic metadata alone. However, the framework’s highest-risk failure modes (data leakage, weak baselines, missing held-out evaluation, circular validation) require checking the paper PDF and supplementary methods.

**Reproducibility (0–3): 2.** This line of work commonly provides sufficient methodological detail and/or some artifacts (code, models, or datasets), but this should be confirmed in the PDF and associated repositories.

**Validation rigor (0–3): 2.** Validation is likely reasonably rigorous (multiple benchmarks or tasks), though the independence of test sets should be verified.

**Claim calibration.** No obvious over-claiming is detectable from the citation metadata alone; confirm by reading the abstract/results to ensure claims match evidence.

**Book relevance (gap filled).** This paper likely supports a core concept, model family, benchmark, or deployment-relevant application that the textbook should teach explicitly.

**Integration cost.** Integration cost: moderate. Recommend adding a short boxed example/figure plus a citation, and referencing it in the relevant chapter narrative.

**Pedagogical value.** Moderate pedagogical value: useful concept, but may require careful framing or simplification.

**Longevity.** Likely to remain relevant (‘textbook test’ passes).

**PDF availability.** Publisher PDF via DOI (may be paywalled).

**Recommendation.** INCLUDE. Suggested book location: Ch05 (genomic sequence modeling).


---

### liu_life-code_2025

Life-Code: Central Dogma Modeling with Multi-Omics Sequence Unification — Liu, Zicheng and Li, Siyuan and Chen, Zhiyuan and Wu, Fang and Yu, Chang and Yang, Qirong and Guo, Yucheng and Yang, Yujie and Zhang, Xiaoming and Li, Stan Z. — arXiv (2025) — DOI: 10.48550/arXiv.2502.07299 — URL: http://arxiv.org/abs/2502.07299

**Scope fit.** Scope fit is unclear from the BibTeX metadata alone; the title/venue do not unambiguously signal deep learning over genomic or protein sequences.

**Recency relevance.** This is recent/modern work (year 2025), aligned with current genomic foundation-model approaches.

**Venue signal.** The BibTeX entry does not specify a venue (journal/conference). This weakens venue signal until a version-of-record is confirmed. Preprint/published-status check: Preprint (arXiv 2025); no journal/conference version found.

**Tier 1 red flags.** No immediate red flags are visible from bibliographic metadata alone. However, the framework’s highest-risk failure modes (data leakage, weak baselines, missing held-out evaluation, circular validation) require checking the paper PDF and supplementary methods.

**Reproducibility (0–3): 1.** Reproducibility is unclear from the citation metadata; assume methods-only unless the PDF provides code/data/weights.

**Validation rigor (0–3): 1.** Validation is likely limited (e.g., single benchmark or closely related datasets), pending PDF verification.

**Claim calibration.** No obvious over-claiming is detectable from the citation metadata alone; confirm by reading the abstract/results to ensure claims match evidence.

**Book relevance (gap filled).** This work is promising but still unsettled (preprint/new results); it may become core if it holds up and gets adopted.

**Integration cost.** Integration cost: low-to-moderate as a sidebar ‘emerging direction’ citation, pending re-evaluation.

**Pedagogical value.** Moderate pedagogical value: useful concept, but may require careful framing or simplification.

**Longevity.** Longevity uncertain; adoption and replication should be monitored.

**PDF availability.** Likely public PDF via preprint server.

**Recommendation.** MONITOR. Suggested book location: Ch05.


---

### medvedev_biotoken_2025

BioToken and BioFM – Biologically-Informed Tokenization Enables Accurate and Efficient Genomic Foundation Models — Medvedev, Aleksandr and Viswanathan, Karthik and Kanithi, Praveenkumar and Vishniakov, Kirill and Munjal, Prateek and Christophe, Clément and Pimentel, Marco AF and Rajan, Ronnie and Khan, Shadab — bioRxiv (2025) — DOI: 10.1101/2025.03.27.645711 — URL: https://www.biorxiv.org/content/10.1101/2025.03.27.645711v1

**Scope fit.** This work is in-scope for the book: it applies deep learning to biological sequences (genomics), with direct relevance to genomic/protein foundation models or downstream tasks.

**Recency relevance.** This is recent/modern work (year 2025), aligned with current genomic foundation-model approaches.

**Venue signal.** The BibTeX entry does not specify a venue (journal/conference). This weakens venue signal until a version-of-record is confirmed. Preprint/published-status check: Preprint (bioRxiv 2025) with code/checkpoints released.

**Tier 1 red flags.** No immediate red flags are visible from bibliographic metadata alone. However, the framework’s highest-risk failure modes (data leakage, weak baselines, missing held-out evaluation, circular validation) require checking the paper PDF and supplementary methods.

**Reproducibility (0–3): 2.** This line of work commonly provides sufficient methodological detail and/or some artifacts (code, models, or datasets), but this should be confirmed in the PDF and associated repositories.

**Validation rigor (0–3): 2.** Validation is likely reasonably rigorous (multiple benchmarks or tasks), though the independence of test sets should be verified.

**Claim calibration.** No obvious over-claiming is detectable from the citation metadata alone; confirm by reading the abstract/results to ensure claims match evidence.

**Book relevance (gap filled).** This work is promising but still unsettled (preprint/new results); it may become core if it holds up and gets adopted.

**Integration cost.** Integration cost: low-to-moderate as a sidebar ‘emerging direction’ citation, pending re-evaluation.

**Pedagogical value.** Moderate pedagogical value: useful concept, but may require careful framing or simplification.

**Longevity.** Longevity uncertain; adoption and replication should be monitored.

**PDF availability.** Likely public PDF via preprint server.

**Recommendation.** MONITOR. Suggested book location: Ch05 (genomic sequence modeling).


---

### nguyen_hyenadna_2023

HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution — Nguyen, Eric and Poli, Michael and Faizi, Marjan and Thomas, Armin and Birch-Sykes, Callum and Wornow, Michael and Patel, Aman and Rabideau, Clayton and Massaroli, Stefano and Bengio, Yoshua and Ermon, Stefano and Baccus, Stephen A. and Ré, Chris — arXiv (2023) — DOI: 10.48550/arXiv.2306.15794 — URL: http://arxiv.org/abs/2306.15794

**Scope fit.** This work is in-scope for the book: it applies deep learning to biological sequences (genomics), with direct relevance to genomic/protein foundation models or downstream tasks.

**Recency relevance.** This is recent/modern work (year 2023), aligned with current genomic foundation-model approaches.

**Venue signal.** The BibTeX entry does not specify a venue (journal/conference). This weakens venue signal until a version-of-record is confirmed. Preprint/published-status check: Published version: NeurIPS 2023 (same title).

**Tier 1 red flags.** No immediate red flags are visible from bibliographic metadata alone. However, the framework’s highest-risk failure modes (data leakage, weak baselines, missing held-out evaluation, circular validation) require checking the paper PDF and supplementary methods.

**Reproducibility (0–3): 2.** This line of work commonly provides sufficient methodological detail and/or some artifacts (code, models, or datasets), but this should be confirmed in the PDF and associated repositories.

**Validation rigor (0–3): 2.** Validation is likely reasonably rigorous (multiple benchmarks or tasks), though the independence of test sets should be verified.

**Claim calibration.** No obvious over-claiming is detectable from the citation metadata alone; confirm by reading the abstract/results to ensure claims match evidence.

**Book relevance (gap filled).** This paper likely supports a core concept, model family, benchmark, or deployment-relevant application that the textbook should teach explicitly.

**Integration cost.** Integration cost: moderate. Recommend adding a short boxed example/figure plus a citation, and referencing it in the relevant chapter narrative.

**Pedagogical value.** High pedagogical value: clean principle or widely-reused method with teachable examples/figures.

**Longevity.** Likely to remain relevant (‘textbook test’ passes).

**PDF availability.** Likely public PDF via preprint server.

**Recommendation.** INCLUDE. Suggested book location: Ch05 (genomic sequence modeling).


---

### sanabria_grover_2024

[GROVER] DNA language model GROVER learns sequence context in the human genome — Sanabria, Melissa and Hirsch, Jonas and Joubert, Pierre M. and Poetsch, Anna R. — Nature Machine Intelligence (2024) — DOI: 10.1038/s42256-024-00872-0 — URL: https://www.nature.com/articles/s42256-024-00872-0

**Scope fit.** This work is in-scope for the book: it applies deep learning to biological sequences (genomics), with direct relevance to genomic/protein foundation models or downstream tasks.

**Recency relevance.** This is recent/modern work (year 2024), aligned with current genomic foundation-model approaches.

**Venue signal.** The venue given in the BibTeX entry is Nature Machine Intelligence. This is generally a credible signal, but final confidence depends on confirming the version-of-record (especially if the entry is a preprint).

**Tier 1 red flags.** No immediate red flags are visible from bibliographic metadata alone. However, the framework’s highest-risk failure modes (data leakage, weak baselines, missing held-out evaluation, circular validation) require checking the paper PDF and supplementary methods.

**Reproducibility (0–3): 2.** This line of work commonly provides sufficient methodological detail and/or some artifacts (code, models, or datasets), but this should be confirmed in the PDF and associated repositories.

**Validation rigor (0–3): 2.** Validation is likely reasonably rigorous (multiple benchmarks or tasks), though the independence of test sets should be verified.

**Claim calibration.** No obvious over-claiming is detectable from the citation metadata alone; confirm by reading the abstract/results to ensure claims match evidence.

**Book relevance (gap filled).** This paper likely supports a core concept, model family, benchmark, or deployment-relevant application that the textbook should teach explicitly.

**Integration cost.** Integration cost: moderate. Recommend adding a short boxed example/figure plus a citation, and referencing it in the relevant chapter narrative.

**Pedagogical value.** Moderate pedagogical value: useful concept, but may require careful framing or simplification.

**Longevity.** Longevity uncertain; adoption and replication should be monitored.

**PDF availability.** Publisher PDF via DOI (may be paywalled).

**Recommendation.** INCLUDE. Suggested book location: Ch05 (genomic sequence modeling).


---

### schiff_caduceus_2024

Caduceus: Bi-Directional Equivariant Long-Range DNA Sequence Modeling — Schiff, Yair and Kao, Chia-Hsiang and Gokaslan, Aaron and Dao, Tri and Gu, Albert and Kuleshov, Volodymyr — arXiv (2024) — DOI: 10.48550/arXiv.2403.03234 — URL: http://arxiv.org/abs/2403.03234

**Scope fit.** This work is in-scope for the book: it applies deep learning to biological sequences (genomics), with direct relevance to genomic/protein foundation models or downstream tasks.

**Recency relevance.** This is recent/modern work (year 2024), aligned with current genomic foundation-model approaches.

**Venue signal.** The BibTeX entry does not specify a venue (journal/conference). This weakens venue signal until a version-of-record is confirmed. Preprint/published-status check: Published version: ICML 2024 (same title).

**Tier 1 red flags.** No immediate red flags are visible from bibliographic metadata alone. However, the framework’s highest-risk failure modes (data leakage, weak baselines, missing held-out evaluation, circular validation) require checking the paper PDF and supplementary methods.

**Reproducibility (0–3): 2.** This line of work commonly provides sufficient methodological detail and/or some artifacts (code, models, or datasets), but this should be confirmed in the PDF and associated repositories.

**Validation rigor (0–3): 2.** Validation is likely reasonably rigorous (multiple benchmarks or tasks), though the independence of test sets should be verified.

**Claim calibration.** No obvious over-claiming is detectable from the citation metadata alone; confirm by reading the abstract/results to ensure claims match evidence.

**Book relevance (gap filled).** This paper likely supports a core concept, model family, benchmark, or deployment-relevant application that the textbook should teach explicitly.

**Integration cost.** Integration cost: moderate. Recommend adding a short boxed example/figure plus a citation, and referencing it in the relevant chapter narrative.

**Pedagogical value.** High pedagogical value: clean principle or widely-reused method with teachable examples/figures.

**Longevity.** Likely to remain relevant (‘textbook test’ passes).

**PDF availability.** Likely public PDF via preprint server.

**Recommendation.** INCLUDE. Suggested book location: Ch05 (genomic sequence modeling).


---

### zhou_dnabert-2_2024

DNABERT-2: Efficient Foundation Model and Benchmark For Multi-Species Genome — Zhou, Zhihan and Ji, Yanrong and Li, Weijian and Dutta, Pratik and Davuluri, Ramana and Liu, Han — arXiv (2024) — DOI: 10.48550/arXiv.2306.15006 — URL: http://arxiv.org/abs/2306.15006

**Scope fit.** This work is in-scope for the book: it applies deep learning to biological sequences (genomics), with direct relevance to genomic/protein foundation models or downstream tasks.

**Recency relevance.** This is recent/modern work (year 2024), aligned with current genomic foundation-model approaches.

**Venue signal.** The BibTeX entry does not specify a venue (journal/conference). This weakens venue signal until a version-of-record is confirmed. Preprint/published-status check: Published version: ICLR 2024 (same title).

**Tier 1 red flags.** No immediate red flags are visible from bibliographic metadata alone. However, the framework’s highest-risk failure modes (data leakage, weak baselines, missing held-out evaluation, circular validation) require checking the paper PDF and supplementary methods.

**Reproducibility (0–3): 2.** This line of work commonly provides sufficient methodological detail and/or some artifacts (code, models, or datasets), but this should be confirmed in the PDF and associated repositories.

**Validation rigor (0–3): 2.** Validation is likely reasonably rigorous (multiple benchmarks or tasks), though the independence of test sets should be verified.

**Claim calibration.** No obvious over-claiming is detectable from the citation metadata alone; confirm by reading the abstract/results to ensure claims match evidence.

**Book relevance (gap filled).** This paper likely supports a core concept, model family, benchmark, or deployment-relevant application that the textbook should teach explicitly.

**Integration cost.** Integration cost: moderate. Recommend adding a short boxed example/figure plus a citation, and referencing it in the relevant chapter narrative.

**Pedagogical value.** High pedagogical value: clean principle or widely-reused method with teachable examples/figures.

**Longevity.** Likely to remain relevant (‘textbook test’ passes).

**PDF availability.** Likely public PDF via preprint server.

**Recommendation.** INCLUDE. Suggested book location: Ch05 (genomic sequence modeling).


---

### zvyagin_genslms_2022

GenSLMs: Genome-scale language models reveal SARS-CoV-2 evolutionary dynamics — Zvyagin, Maxim and Brace, Alexander and Hippe, Kyle and Deng, Yuntian and Zhang, Bin and Bohorquez, Cindy Orozco and Clyde, Austin and Kale, Bharat and Perez-Rivera, Danilo and Ma, Heng and Mann, Carla M. and Irvin, Michael and Pauloski, J. Gregory and Ward, Logan and Hayot-Sasson, Valerie and Emani, Murali and Foreman, Sam and Xie, Zhen and Lin, Diangen and Shukla, Maulik and Nie, Weili and Romero, Josh and Dallago, Christian and Vahdat, Arash and Xiao, Chaowei and Gibbs, Thomas and Foster, Ian and Davis, James J. and Papka, Michael E. and Brettin, Thomas and Stevens, Rick and Anandkumar, Anima and Vishwanath, Venkatram and Ramanathan, Arvind — bioRxiv (2022) — DOI: 10.1101/2022.10.10.511571 — URL: https://www.biorxiv.org/content/10.1101/2022.10.10.511571v2

**Scope fit.** This work is in-scope for the book: it applies deep learning to biological sequences (genomics), with direct relevance to genomic/protein foundation models or downstream tasks.

**Recency relevance.** This is recent/modern work (year 2022), aligned with current genomic foundation-model approaches.

**Venue signal.** The BibTeX entry does not specify a venue (journal/conference). This weakens venue signal until a version-of-record is confirmed. Preprint/published-status check: Preprint (bioRxiv 2022); no clear journal/conference version found.

**Tier 1 red flags.** No immediate red flags are visible from bibliographic metadata alone. However, the framework’s highest-risk failure modes (data leakage, weak baselines, missing held-out evaluation, circular validation) require checking the paper PDF and supplementary methods.

**Reproducibility (0–3): 2.** This line of work commonly provides sufficient methodological detail and/or some artifacts (code, models, or datasets), but this should be confirmed in the PDF and associated repositories.

**Validation rigor (0–3): 2.** Validation is likely reasonably rigorous (multiple benchmarks or tasks), though the independence of test sets should be verified.

**Claim calibration.** No obvious over-claiming is detectable from the citation metadata alone; confirm by reading the abstract/results to ensure claims match evidence.

**Book relevance (gap filled).** This paper likely supports a core concept, model family, benchmark, or deployment-relevant application that the textbook should teach explicitly.

**Integration cost.** Integration cost: moderate. Recommend adding a short boxed example/figure plus a citation, and referencing it in the relevant chapter narrative.

**Pedagogical value.** Moderate pedagogical value: useful concept, but may require careful framing or simplification.

**Longevity.** Likely to remain relevant (‘textbook test’ passes).

**PDF availability.** Likely public PDF via preprint server.

**Recommendation.** INCLUDE. Suggested book location: Ch05 (genomic sequence modeling).


---
